{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part A: Preprocessing of imaging data**  \n",
    "<i>**Latest update</i> - Jan 2025**  \n",
    "\n",
    "#### **Authors:**  \n",
    "[Thomas O'Neil](https://github.com/DrThomasOneil) (thomas.oneil@sydney.edu.au) | [Oscar Dong](https://github.com/Awesomenous) (oscardong4@gmail.com) | [Heeva Baharlou](heeva.baharlou@sydney.edu.com)  \n",
    "\n",
    "##### The purpose of this notebook is to provide a consolidated approach to IMC analysis and forms the prerequisite steps to the IMComplete R package workflow. We focused \n",
    "\n",
    "Nature Method of the Year in 2024 was [**spatial proteomics**](https://www.nature.com/articles/s41592-024-02565-3). \n",
    "\n",
    "> Computational tools for spatial proteomics are the focus of the second Comment, from Yuval Bussi and Leeat Keren. These authors note that current image processing and analysis workflow are **well defined but fragmented**, with various steps happening back to back **rather than in an integrated fashion**. They envision a future for the field where **image processing and analysis steps work in concert** for improved biological discovery.\n",
    "\n",
    "In alignment to these comments, we have committed to provide a comprehensive and dynamic workflow. In part, we aimed to achieve this by compiling as much as we could into this pre-processing workflow. \n",
    "\n",
    "Particularly, we have emphasised tools that can be performed in <strong>*one*</strong> workflow. For example, we introduce here `PyProfiler`, a tool that performs the same functions as Cell Profiler, allowing users to not leave this linear workflow and install additional applications.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Some scripts adapted from [BodenmillerGroup/ImcSegmentationPipeline](https://github.com/BodenmillerGroup/ImcSegmentationPipeline) & [PENGLU-WashU/IMC_Denoise](https://github.com/PENGLU-WashU/IMC_Denoise) \n",
    "\n",
    "<i>**Therefore, make sure to also reference these studies:**</i>  \n",
    "- Windhager, J., Zanotelli, V.R.T., Schulz, D. et al. An end-to-end workflow for multiplexed image processing and analysis. [Nat Protoc](https://doi.org/10.1038/s41596-023-00881-0) (2023).  \n",
    "- Lu P, Oetjen K, Bender D, et al. IMC-Denoise: a content aware pipeline to enhance Imaging Mass Cytometry. [Nature Communications](https://www.nature.com/articles/s41467-023-37123-6), 14(1), 1601, 2023.  \n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "##### Planned future additions:  \n",
    "- Simple compartmentalisation in python widget\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "## Folder structure\n",
    "\n",
    "```text\n",
    "ImagingAnalysis/ (root directory)\n",
    "├── IMComplete-Workflow\n",
    "├── ImcSegmentationPipeline\n",
    "├── Experiment_name_1\n",
    "│     └── raw\n",
    "│            └── Sample1.zip\n",
    "│            └── Sample2.zip\n",
    "│            └── ...\n",
    "│     └── analysis\n",
    "│            └── 1_image_out\n",
    "│            └── 2_cleaned\n",
    "│            └── 3_segmentation\n",
    "│                   └── 3a_cellpose_crop\n",
    "│                   └── 3b_cellpose_full\n",
    "│                   └── 3c_cellpose_mask\n",
    "│                   └── 3d_compartments\n",
    "│            └── 4_pyprofiler_output\n",
    "│     └── panel.csv\n",
    "├── ...\n",
    "├── Experiment_name_\n",
    "```\n",
    "<br>\n",
    "<hr> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "1. Set up (`CheckSetup()`) ✅ \n",
    "\n",
    "2. Create a new project (`NewProject()`) ✅ \n",
    "\n",
    "3. Prep the raw folder and `panel.csv` ✅ \n",
    "\n",
    "4. Extract images from the raw folder (`ExtractImages()`) ✅ \n",
    "\n",
    "- *Optional 1:* Check filter parameters of IF data ✅ \n",
    "\n",
    "- *Optional 2:* Filter images (`FilterImages()`) ✅ \n",
    "\n",
    "- *Optional 3:* Select crop regions for segmentation training (`CropSelector()`) ✅ \n",
    "\n",
    "5. Prepare the images for Segmentation model training (`PrepCellpose()`) ✅ \n",
    "\n",
    "- *Optional 4:* Register low-resolution images with high-resolution images to improve cell segmentation  ✅ \n",
    "\n",
    "6. Train a segmentation model (`cellpose`) ✅ \n",
    "\n",
    "- *Optional 5:* You have the option to not train a segmentation model and use a generic model.  ✅ \n",
    "\n",
    "7. Batch segment the images and generate cell masks (`BatchSegment()`)\n",
    "\n",
    "- *Optional 6 <strong>in development</strong>:* Generate masks for compartments or distance metrics. (*Currently in ImageJ/Qupath* - want to add simple `add_compartment_mask()` or `add_threshold_mask()`) \n",
    "\n",
    "8. Extract data from your images using the cell segment masks (`PyProfiler()`)\n",
    "\n",
    "<hr><hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Set up\n",
    "\n",
    "Anaconda is a program needed to run many steps of the workflow, primarily during setup. Follow the steps below to set up Anaconda and a `conda` environment:\n",
    "\n",
    "Install [**Anaconda** ](https://www.anaconda.com/download) and navigate to the relevant command line interface:\n",
    "<br>\n",
    "<div align=\"left\">\n",
    "\n",
    "| Windows                                                                                            | macOS                                                                                                      |\n",
    "|----------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|\n",
    "| 1. Search for **'Anaconda Prompt'** in the taskbar search <br> 2. Select **Anaconda Prompt**  <br> | 1. Use `cmd + space` to open Spotlight Search  <br> 2. Type **'Terminal'** and press `return` to open <br> |\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<hr><hr>\n",
    "\n",
    "### *Using Anaconda...*\n",
    "\n",
    "#### **Step 1:** Set your directory to the analysis folder (or the `root directory` for image analysis)\n",
    "\n",
    "```bash\n",
    "cd /Desktop/ImageAnalysis\n",
    "```\n",
    "<hr>\n",
    "\n",
    "#### **Step 2:** Clone the IMComplete repository.\n",
    "\n",
    "<storng>*From Github*</strong>  \n",
    "Go to the [Github page](https://github.com/CVR-MucosalImmunology/IMComplete-Workflow) and near the top click the `code` button and download the zip. Unzip the folder into the `root` directory. This will contain the IMComplete-Workflow documents and allow ready access to the necessary files.\n",
    "\n",
    "</strong>*Using Git*</strong> in command line\n",
    "\n",
    "<details><summary>Install Git</summary>\n",
    "\n",
    "Git needs to be installed on your system. Find the instructions [here](https://git-scm.com/downloads)\n",
    "\n",
    "<hr></details>\n",
    "\n",
    "```bash\n",
    "git clone --recursive https://github.com/CVR-MucosalImmunology/IMComplete-Workflow.git\n",
    "``` \n",
    "<hr>\n",
    "\n",
    "#### **Step 3:** Clone the extra repositories: \n",
    "\n",
    "- [BodenmillerGroup/ImcSegmentationPipeline](https://github.com/BodenmillerGroup/ImcSegmentationPipeline): Windhager, J., Zanotelli, V.R.T., Schulz, D. et al. An end-to-end workflow for multiplexed image processing and analysis. [Nat Protoc](https://doi.org/10.1038/s41596-023-00881-0) (2023).  \n",
    "\n",
    "```bash\n",
    "git clone --recursive https://github.com/BodenmillerGroup/ImcSegmentationPipeline.git\n",
    "```\n",
    "<!---  \n",
    "- [deMirandaLab/PENGUIN](https://github.com/deMirandaLab/PENGUIN): Sequeira, A. M., Ijsselsteijn, M. E., Rocha, M., & de Miranda, N. F. (2024). PENGUIN: A rapid and efficient image preprocessing tool for multiplexed spatial proteomics. [Computational and Structural Biotechnology Journal](https://doi.org/10.1101/2024.07.01.601513)\n",
    "```bash\n",
    "git clone --recursive https://github.com/deMirandaLab/PENGUIN.git\n",
    "```\n",
    "<--->\n",
    "\n",
    "<hr>\n",
    "\n",
    "#### **Step 4:** Create a conda environment and install some  packages (in one line)\n",
    "\n",
    "```bash\n",
    "conda env create -f IMComplete-Workflow/environment.yml\n",
    "```\n",
    "\n",
    "*This can take some time so be patient!*\n",
    "\n",
    "<hr>\n",
    "\n",
    "#### **Step 5:** Activate the newly created conda environment\n",
    "\n",
    "```bash\n",
    "conda activate IMComplete\n",
    "```\n",
    "\n",
    "<hr>\n",
    "\n",
    "#### **Step 6:** Activate and ensure your GPU-acceleration\n",
    "\n",
    "Unfortunately, parts of this workflow will require GPU-acceleration: Cell segmentation, Denoise, PyProfiler (will run quicker, but not necessary).\n",
    "\n",
    "You will need to install Pytorch and pytorch-cuda versions that are suitable for your PC. Instructions are found [here](https://pytorch.org/get-started/previous-versions/). The code will look like this:\n",
    "\n",
    "```bash\n",
    "conda install pytorch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 pytorch-cuda=12.4 -c pytorch -c nvidia\n",
    "```\n",
    "\n",
    "<hr>\n",
    "\n",
    "#### **Step 7:** Select the IMComplete kernel in your IDE\n",
    "\n",
    "If you are using VSCode, you'll see this option in the top right of the window. \n",
    "\n",
    "If you are using a jupyter notebook, you will see this...<span style=\"color:white; background:red\">[TO ADD]</span>\n",
    "\n",
    "<hr><hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Function: CheckSetup()`\n",
    "\n",
    "You can check the installation requirements with the following function:\n",
    "\n",
    "<details><summary>Information</summary>\n",
    "\n",
    "```bash\n",
    "\n",
    "CheckSetup(\n",
    "    torch=1\n",
    "    )\n",
    "\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Arguments:**  \n",
    "- `torch`: Default is `1` which simply checks that GPU is installed and ready. This can be turned off if you're using a Mac and/or aware that GPU is not properly setup.\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Expected Outputs:**\n",
    "\n",
    "```text\n",
    "Checking required packages in the current Conda environment...\n",
    "\n",
    "  All required packages are installed and meet the required versions.\n",
    "\n",
    "-----------------\n",
    "\n",
    "Checking that CUDA has been installed properly...\n",
    "\n",
    "  GPU acceleration has not been prepared. Consult https://pytorch.org/get-started/previous-versions/\n",
    "  and try again\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Packages:**   \n",
    "- pkg_resources\n",
    "\n",
    "================================================================\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "def CheckSetup(torch=1):\n",
    "    \"\"\"\n",
    "    Checks for required Python packages and verifies CUDA installation.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of missing or insufficient packages with their required versions.\n",
    "    \"\"\"\n",
    "    print(\"Checking required packages in the current Conda environment...\\n\")\n",
    "    \n",
    "    required_packages = {\n",
    "\n",
    "        \"imcsegpipe\": \"1.0.0\",\n",
    "        \"pymcomplete\":\"\",\n",
    "        \"readimc\": \"0.8.0\",\n",
    "        \"pip\": \"\",\n",
    "        \"numpy\": \"\",\n",
    "        \"jupyter\" : \"\",\n",
    "        \"jupyterlab\": \"\",\n",
    "        \"jupytext\": \"\",\n",
    "        \"cellpose\" : \"\",\n",
    "        \"pyqtgraph\": \"\",\n",
    "        \"numba\": \"\",\n",
    "        \"scipy\": \"\",\n",
    "        \"natsort\": \"\",\n",
    "        \"tifffile\": \"2024.8.10\",\n",
    "        \"brotlipy\": \"\",\n",
    "        \"matplotlib\": \"\",\n",
    "        \"pandas\": \"\", \n",
    "        \"panel\": \"\", \n",
    "        \"opencv-python\": \"\", \n",
    "        \"scikit-image\": \"\",\n",
    "        \"ipywidgets\" : \"\",\n",
    "        \"ipykernel\" : \"\",\n",
    "        \"ipympl\": \"\",\n",
    "        \"plotly\": \"\",\n",
    "        \"ttkbootstrap\":\"\", \n",
    "        \"PyQt5\":\"\",\n",
    "    }\n",
    "\n",
    "    missing_packages = {}\n",
    "\n",
    "    for package, version in required_packages.items():\n",
    "        try:\n",
    "            installed_version = pkg_resources.get_distribution(package).version\n",
    "            if version and pkg_resources.parse_version(installed_version) < pkg_resources.parse_version(version):\n",
    "                missing_packages[package] = version\n",
    "        except pkg_resources.DistributionNotFound:\n",
    "            missing_packages[package] = version\n",
    "\n",
    "    if missing_packages:\n",
    "        print(\"The following packages are missing or have insufficient versions:\")\n",
    "        for package, version in missing_packages.items():\n",
    "            if version:\n",
    "                print(f\" - {package} (required version: {version})\")\n",
    "            else:\n",
    "                print(f\" - {package} (no version specified)\")\n",
    "    else:\n",
    "        print(\"  All required packages are installed and meet the required versions.\")\n",
    "\n",
    "    if torch:\n",
    "        import torch\n",
    "        print(\"\\n-----------------\\n\\nChecking that CUDA has been installed properly...\\n\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"  GPU acceleration via CUDA is available\")\n",
    "        else:\n",
    "            print(\"  GPU acceleration has not been prepared. Consult https://pytorch.org/get-started/previous-versions/\\nand try again\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyMComplete import CheckSetup\n",
    "\n",
    "CheckSetup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Set up a new Project for Imaging Analysis\n",
    "\n",
    "The following function will create the folder structure for this workflow and generate a template `panel.csv` and `image.csv`.\n",
    "\n",
    "Set `rootdir` as your **ImageAnalysis** folder directory and `projdir` as your **project** folder name.\n",
    "\n",
    "**Important**: These need to established each time you open this workflow, as all subsequent folders will rely on these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"/Users/thomasoneil/Desktop/test_IF\"\n",
    "projdir = \"LizIMCIFReg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Function: NewProject()`\n",
    "\n",
    "The workflow is designed to utilize both a `rootdir` and a `projdir` for better organization and efficiency.\n",
    "\n",
    "- `rootdir`: This directory is intended to store commonly used GitHub Repositories and other relevant resources.  \n",
    "\n",
    "- `projdir`: This directory is specific to individual projects. \n",
    "\n",
    "By structuring the directories this way, users with multiple projects can benefit from a consistent workflow. They only need to install the repositories once in the `rootdir`, and all projects can access these resources without duplication. This approach eliminates the need to repeatedly refer to or duplicate distant folders, streamlining the workflow and ensuring all relevant files are easily accessible.\n",
    "\n",
    "<details><summary>Information</summary>\n",
    "\n",
    "```bash\n",
    "NewProject(\n",
    "    rootdir=rootdir, \n",
    "    projdir=projdir\n",
    "    )\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Arguments:**  \n",
    "- `rootdir`: This directory is intended to store commonly used GitHub Repositories and other relevant resources.  \n",
    "\n",
    "- `projdir`: This directory is specific to individual projects. \n",
    "\n",
    "================================================================\n",
    "\n",
    "**Expected Outputs:**\n",
    "\n",
    "```text\n",
    "Project '2025_ProjectName' created successfully.\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Packages:**   \n",
    "- os\n",
    "- csv\n",
    "\n",
    "================================================================\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def NewProject(rootdir, projdir):\n",
    "    \"\"\"\n",
    "    Creates a structured project folder with the given root directory and project name.\n",
    "\n",
    "    Args:\n",
    "        rootdir (str): The root directory where the project will be created.\n",
    "        project_name (str): The name of the new project folder.\n",
    "    \"\"\"\n",
    "    if os.path.isdir(os.path.join(rootdir,projdir)):\n",
    "        print(\"Directory does not exist\") \n",
    "        return\n",
    "\n",
    "    # Define all required subdirectories\n",
    "    acquisitions_dir = os.path.join(rootdir, projdir, \"analysis/1_image_out\")\n",
    "    cleaned_dir = os.path.join(rootdir, projdir, \"analysis/2_cleaned\")\n",
    "    segment_fold_dir = os.path.join(rootdir, projdir, \"analysis/3_segmentation\")\n",
    "    crop_output = os.path.join(segment_fold_dir, \"3a_cellpose_crop\")\n",
    "    im_output = os.path.join(segment_fold_dir, \"3b_cellpose_full\")\n",
    "    mask_dir = os.path.join(segment_fold_dir, \"3c_cellpose_mask\")\n",
    "    compart = os.path.join(segment_fold_dir, \"3d_compartments\")\n",
    "    pyprof_out = os.path.join(rootdir, projdir, \"analysis/4_cellprofiler_output\")\n",
    "    R_out = os.path.join(rootdir, projdir, \"analysis/5_R_analysis\")\n",
    "    #meta_out = os.path.join(rootdir, projdir, \".meta\")\n",
    "\n",
    "    # Create directories\n",
    "    os.makedirs(os.path.join(rootdir, projdir), exist_ok=True)\n",
    "    os.makedirs(os.path.join(rootdir, projdir, \"raw\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(rootdir, projdir, \"analysis\"), exist_ok=True)\n",
    "    os.makedirs(acquisitions_dir, exist_ok=True)\n",
    "    os.makedirs(cleaned_dir, exist_ok=True)\n",
    "    os.makedirs(segment_fold_dir, exist_ok=True)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(segment_dir, exist_ok=True)\n",
    "    os.makedirs(crop_output, exist_ok=True)\n",
    "    os.makedirs(im_output, exist_ok=True)\n",
    "    os.makedirs(mask_dir, exist_ok=True)\n",
    "    os.makedirs(compart, exist_ok=True)\n",
    "    os.makedirs(pyprof_out, exist_ok=True)\n",
    "    os.makedirs(R_out, exist_ok=True)\n",
    "\n",
    "    print(f\"Project '{projdir}' created successfully.\")\n",
    "\n",
    "    # Data to be written to the CSV file\n",
    "    panel = [\n",
    "        [\"Conjugate\", \"Target\", \"Full\", \"Segment\"]\n",
    "    ]\n",
    "\n",
    "    # Specify the file name\n",
    "    filename = os.path.join(rootdir, projdir, \"panel.csv\")\n",
    "\n",
    "    # Writing to the CSV file\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyMComplete import NewProject\n",
    "\n",
    "NewProject(\n",
    "    rootdir=rootdir, \n",
    "    projdir=projdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set up your `raw` folder \n",
    "\n",
    "### **For IMC data**\n",
    "\n",
    "Your IMC data should be zipped in a specific format. Our IMC image extraction utilises the imcsegpipe package developed by **Windhager et al. 2023**. Therefore, we opted to match the file format suggested for that workflow. The following was taken from the **Bodenmiller** [**Preprocessing instructions**.](https://bodenmillergroup.github.io/ImcSegmentationPipeline/prepro.html)\n",
    "\n",
    "<span style=\"color:grey\">*The Hyperion Imaging System produces vendor controlled .mcd and .txt files in the following folder structure:*</span>\n",
    "\n",
    "```text\n",
    "Sample1.zip\n",
    "├── {XYZ}_ROI_001_1.txt\n",
    "├── {XYZ}_ROI_002_2.txt\n",
    "├── {XYZ}_ROI_003_3.txt\n",
    "├── {XYZ}.mcd\n",
    "...\n",
    "```\n",
    "<span style=\"color:grey\">*where `XYZ` defines the filename, `ROI_001`, `ROI_002`, `ROI_003` are names (description) for the selected regions of interest (ROI) and `1`, `2`, `3` indicate the acquistion identifiers. The ROI description entry can be specified in the Fluidigm software when selecting ROIs. The `.mcd` file contains the raw imaging data of all acquired ROIs while each `.txt` file contains data of a single ROI. To enforce a consistent naming scheme and to bundle all metadata, we recommend to zip the folder and specify the location of all `.zip` files for preprocessing. Each `.zip` file should only contain data from a single `.mcd` file and the name of the `.zip` file should match the name of the `.mcd` file.*</span>\n",
    "\n",
    "<suoerscript>**Citation:**   \n",
    "*Windhager, J., Zanotelli, V.R.T., Schulz, D. et al. An end-to-end workflow for multiplexed image processing and analysis. Nat Protoc (2023). https://doi.org/10.1038/s41596-023-00881-0*</superscript>\n",
    "\n",
    "### **For IF data**\n",
    "\n",
    "Images *currently* need be a `.tiff` image as a stack inside a folder of the same name. \n",
    "\n",
    "```text\n",
    "Image1/\n",
    "├── Image1.tiff\n",
    "Image2/\n",
    "├── Image2.tiff\n",
    "...\n",
    "```\n",
    "\n",
    "In the future, we will try to adjust the requirements to match the general output\n",
    "<hr><hr>\n",
    "\n",
    "# Edit the panel\n",
    "\n",
    "The panel.csv file in the projdir needs to match the stack order of your images, including empty channels\n",
    "\n",
    "There are *currently* four columns in the default panel.csv:\n",
    "\n",
    "- **Conjugate**: The metal tag or fluorophore.\n",
    "\n",
    "- **Target**: The name of the target antibody. Try to avoid using a numeric at the start of the name. \n",
    "\n",
    "- **Full**: Should be filled with a `1` if this channel is an image you want to extract. \n",
    "\n",
    "- **Segment**: Should be filled with a `1` if this includes a marker for Segmentation. \n",
    "\n",
    "You can add as many additional columns as you like that may aide your analysis further down.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Extract images from the raw folder\n",
    "\n",
    "This is a simple step that extracts the image data from the raw folders and saves them as stacked `.tiff` files in `analysis/1_image_out`.\n",
    "\n",
    "For **IMC**, the Bodenmiller `extract_mcd_file()` function will convert the `.mcd` and `.txt` files to separate `.tiff` stacks. \n",
    "\n",
    "For **IF**, simply the images are moved. Currently, this function works such that each IF stack requires its own folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Function: ExtractImages()`\n",
    "\n",
    "This function extracts images if they're IMC, or copies them if they're immunfluorescent or in .tiff format, and deposits them in an `extract_dir`. \n",
    "\n",
    "<details><summary>Information</summary>\n",
    "\n",
    "```bash\n",
    "ExtractImages(\n",
    "    rootdir = rootdir,\n",
    "    projdir = projdir,\n",
    "    format = \"if\",\n",
    "    rawimage_dir = \"raw\",\n",
    "    extract_dir = \"analysis/1_image_out\")\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Arguments:**  \n",
    "- `rootdir`: This directory is intended to store commonly used GitHub Repositories and other relevant resources.  \n",
    "\n",
    "- `projdir`: This directory is specific to individual projects. \n",
    "\n",
    "- `format`: This argument strictly takes `if` or `imc` and processes the images accordingly. \n",
    "\n",
    "- `rawimage_dir`: This argument specifies where the raw images are stored. The default is **\"raw\"**.\n",
    "\n",
    "- `extract_dir`: This argument specifies where the raw images are deposited. The default is **\"analysis/1_image_out\"**.\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Expected Outputs:**\n",
    "\n",
    "```text\n",
    "Extracting Immunofluorescent Images...\n",
    "Done!\n",
    "```\n",
    "```text\n",
    "Extracting IMC images using Bodenmiller's extract_zip_file function ...\n",
    "Done!\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Packages:**   \n",
    "- pathlib\n",
    "- tempfile\n",
    "- imcsegpipe\n",
    "\n",
    "================================================================\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "\n",
    "def ExtractImages(rootdir:str,\n",
    "                   projdir:str,\n",
    "                   format:str,\n",
    "                   rawimage_dir = \"raw\",\n",
    "                   extract_dir = \"analysis/1_image_out\"):\n",
    "    \n",
    "    project_path = Path(rootdir) / projdir\n",
    "    images_dir = project_path / extract_dir\n",
    "    raw = project_path / rawimage_dir\n",
    "    \n",
    "    if format == \"if\":\n",
    "        print(\"Extracting Immunofluorescent Images...\\n\")\n",
    "        for sample_dir in raw.iterdir():\n",
    "            if not sample_dir.is_dir() or sample_dir.name.startswith(\".\"):\n",
    "                continue\n",
    "\n",
    "            # Create subfolder in analysis/1_image_out\n",
    "            acquisition_subdir = images_dir / sample_dir.name\n",
    "            acquisition_subdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Final stacked TIFF path\n",
    "            out_tiff_path = acquisition_subdir / f\"{sample_dir.name}.tiff\"\n",
    "\n",
    "            # We expect exactly one TIF in the folder\n",
    "            tif_files = list(sample_dir.glob(\"*.tif*\"))\n",
    "            if len(tif_files) != 1:\n",
    "                raise ValueError(\n",
    "                    f\"Expected exactly 1 TIF in '{sample_dir.name}', found {len(tif_files)}.\"\n",
    "                )\n",
    "            single_tif = tif_files[0]\n",
    "\n",
    "            # Read the stack\n",
    "            image = io.imread(str(single_tif))\n",
    "\n",
    "            # Validate that the stack depth == number of rows in panel.csv\n",
    "            if image.shape[0] != len(panel):\n",
    "                raise ValueError(\n",
    "                    f\"Panel length is {len(panel)} but found `{image.shape[0]}` channels\"\n",
    "                    f\" in '{sample_dir.name}'.\"\n",
    "                )\n",
    "\n",
    "            # Save the original stack (unprocessed or raw)\n",
    "            io.imsave(str(out_tiff_path), image)\n",
    "        print(\"Done!\\n\")\n",
    "\n",
    "    if format == \"imc\":\n",
    "        print(\"Extracting IMC images using Bodenmiller's extract_zip_file function ...\\n\")\n",
    "\n",
    "        from tempfile import TemporaryDirectory\n",
    "        import imcsegpipe\n",
    "                \n",
    "        temp_dirs = []\n",
    "        try:\n",
    "            for raw_dir in [raw]:\n",
    "                zip_files = list(raw_dir.rglob(\"**/*.zip\"))\n",
    "                if len(zip_files) > 0:\n",
    "                    temp_dir = TemporaryDirectory()\n",
    "                    temp_dirs.append(temp_dir)\n",
    "                    for zip_file in sorted(zip_files):\n",
    "                        imcsegpipe.extract_zip_file(zip_file, temp_dir.name)\n",
    "            for raw_dir in [raw] + [Path(temp_dir.name) for temp_dir in temp_dirs]:\n",
    "                mcd_files = list(raw_dir.rglob(\"*.mcd\"))\n",
    "                mcd_files = [i for i in mcd_files if not i.stem.startswith('.')]\n",
    "                if len(mcd_files) > 0:\n",
    "                    txt_files = list(raw_dir.rglob(\"*.txt\"))\n",
    "                    txt_files = [i for i in txt_files if not i.stem.startswith('.')]\n",
    "                    matched_txt_files = imcsegpipe.match_txt_files(mcd_files, txt_files)\n",
    "                    for mcd_file in mcd_files:\n",
    "                        imcsegpipe.extract_mcd_file(\n",
    "                            mcd_file,\n",
    "                            images_dir / mcd_file.stem,\n",
    "                            txt_files=matched_txt_files[mcd_file]\n",
    "                        )\n",
    "        finally:\n",
    "            for temp_dir in temp_dirs:\n",
    "                temp_dir.cleanup()\n",
    "            del temp_dirs\n",
    "\n",
    "        print(\"Done!\")\n",
    "\n",
    "    # Create image.csv\n",
    "    image_data = []\n",
    "    for subdir in images_dir.iterdir():\n",
    "        if subdir.is_dir():\n",
    "            for tiff_file in subdir.glob(\"*.tiff\"):\n",
    "                image_data.append({\n",
    "                    \"Image\": tiff_file.stem,\n",
    "                    \"ImShort\": \"\",  # Example short name, adjust as needed\n",
    "                    \"ROI\": \"\",  # Placeholder, adjust as needed\n",
    "                    \"ImageID\": \"\",  # Example ID, adjust as needed\n",
    "                    \"DonorID\": \"\",  # Placeholder, adjust as needed\n",
    "                    \"Condition\": \"\",  # Placeholder, adjust as needed\n",
    "                    \"Crop\": \"\"  # Placeholder, adjust as needed\n",
    "                })\n",
    "\n",
    "    image_df = pd.DataFrame(image_data)\n",
    "    image_csv_path = images_dir / \"image.csv\"\n",
    "    image_df.to_csv(image_csv_path, index=False)\n",
    "    print(f\"image.csv created at {image_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyMComplete imoprt ExtractImages\n",
    "\n",
    "ExtractImages(\n",
    "    rootdir = rootdir,\n",
    "    projdir = projdir,\n",
    "    format = \"if\") # or \"imc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional steps\n",
    "\n",
    "### Optional 1: Check the filter parameters for IF images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Function: CheckExtract()`\n",
    "\n",
    "This function lets you check the filter parameters for your IF images. \n",
    "\n",
    "<details><summary>Information</summary>\n",
    "\n",
    "```bash\n",
    "CheckExtract(\n",
    "    rootdir = rootdir,\n",
    "    projdir = projdir,\n",
    "    extract_dir =\"analysis/1_image_out\",\n",
    "    panel_path = \"panel.csv\",\n",
    "    crop=None\n",
    ")\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Arguments:**  \n",
    "- `rootdir`: This directory is intended to store commonly used GitHub Repositories and other relevant resources.  \n",
    "\n",
    "- `projdir`: This directory is specific to individual projects. \n",
    "\n",
    "- `extract_dir`: This argument specifies where the images are. The default is **\"analysis/1_image_out\"**.\n",
    "\n",
    "- `panel_path`: This argument points to the panel.csv. The function will use the names in the `Target` column for the drop down options. \n",
    "\n",
    "- `crop`: Specifies the size of a random cropped area. The value correlates to the square size in pixels. When Update is clicked, a new crop is randomly shown. Default is None. \n",
    "\n",
    "================================================================\n",
    "\n",
    "**Expected Outputs:**\n",
    "\n",
    "A Jupyter widget that allows you to visualise how hotpixel and guassian blur values will affect your images. \n",
    "\n",
    "================================================================\n",
    "\n",
    "**Packages:**   \n",
    "- pathlib\n",
    "- numpy\n",
    "- pandas\n",
    "- tifffile\n",
    "- matplotlib\n",
    "- ipywidgets\n",
    "- IPython.display\n",
    "- skimage\n",
    "- skiimage.filters\n",
    "- scipy.ndimage\n",
    "\n",
    "================================================================\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from skimage import img_as_float\n",
    "from skimage.filters import gaussian\n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "\n",
    "def CheckExtract(\n",
    "    rootdir:str,\n",
    "    projdir:str,\n",
    "    extract_dir =\"analysis/1_image_out\",\n",
    "    panel_path = \"panel.csv\",\n",
    "    crop=None\n",
    "):\n",
    "    def remove_hotpixels_threshold(img, threshold=5.0, neighborhood_size=3):\n",
    "        \"\"\"\n",
    "        Replace 'hot' pixels that are above (threshold * local_mean) with that local mean.\n",
    "        \"\"\"\n",
    "        img_float = img_as_float(img)\n",
    "        local_mean = uniform_filter(img_float, size=neighborhood_size)\n",
    "        hot_mask = img_float > (threshold * local_mean)\n",
    "        cleaned_img = img_float.copy()\n",
    "        cleaned_img[hot_mask] = local_mean[hot_mask]\n",
    "        return cleaned_img\n",
    "\n",
    "    def apply_gaussian_blur(img, sigma=1.0):\n",
    "        \"\"\"\n",
    "        Applies a Gaussian blur with a given sigma.\n",
    "        \"\"\"\n",
    "        # preserve_range=True ensures we keep original intensity scale\n",
    "        blurred = gaussian(img, sigma=sigma, preserve_range=True)\n",
    "        return blurred\n",
    "\n",
    "    def process_channel(img, hp_threshold=None, hp_neighborhood=3, gauss_sigma=None):\n",
    "        \"\"\"\n",
    "        Given a single 2D channel image:\n",
    "        - If hp_threshold is not None, remove hotpixels.\n",
    "        - If gauss_sigma is not None, apply Gaussian blur.\n",
    "        Returns the processed image.\n",
    "        \"\"\"\n",
    "        processed = img.copy()\n",
    "\n",
    "        if hp_threshold is not None:\n",
    "            processed = remove_hotpixels_threshold(\n",
    "                processed,\n",
    "                threshold=hp_threshold,\n",
    "                neighborhood_size=hp_neighborhood\n",
    "            )\n",
    "        if gauss_sigma is not None:\n",
    "            processed = apply_gaussian_blur(processed, sigma=gauss_sigma)\n",
    "\n",
    "        return processed\n",
    "\n",
    "    def random_crop_2D(img, crop_size=200):\n",
    "        \"\"\"\n",
    "        Returns a random crop of shape (crop_size, crop_size) from a 2D image.\n",
    "        \"\"\"\n",
    "        h, w = img.shape\n",
    "        if crop_size > h or crop_size > w:\n",
    "            raise ValueError(f\"Crop size {crop_size}×{crop_size} is larger than image {h}×{w}.\")\n",
    "        # Random top-left corner\n",
    "        y = np.random.randint(0, h - crop_size + 1)\n",
    "        x = np.random.randint(0, w - crop_size + 1)\n",
    "        return img[y:y+crop_size, x:x+crop_size]\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 1. Locate directories and panel\n",
    "    # --------------------------------------------------------------------------\n",
    "    project_path = Path(rootdir) / projdir \n",
    "    image_dir = project_path / extract_dir\n",
    "    \n",
    "    panel_path = project_path / panel_path\n",
    "\n",
    "    if not os.path.exists(panel_path):\n",
    "        raise FileNotFoundError(f\"Panel file not found: {panel_path}\")\n",
    "\n",
    "    panel = pd.read_csv(panel_path)\n",
    "    if \"Target\" not in panel.columns:\n",
    "        raise ValueError(\"panel.csv must contain a 'Target' column for channel names.\")\n",
    "\n",
    "    # We'll use the \"Target\" column as channel names\n",
    "    channel_names = panel[\"Target\"].tolist()\n",
    "    num_channels = len(channel_names)\n",
    "\n",
    "    # Gather subfolders in image_dir (these are our 'images')\n",
    "    subfolders = [\n",
    "        d for d in os.listdir(image_dir)\n",
    "        if os.path.isdir(os.path.join(image_dir, d)) and not d.startswith('.')\n",
    "    ]\n",
    "\n",
    "    if not subfolders:\n",
    "        raise ValueError(f\"No subfolders found in {image_dir}.\")\n",
    "\n",
    "    image_dropdown = widgets.Dropdown(\n",
    "        options=subfolders,\n",
    "        description='Image:',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "\n",
    "    # Dropdown to pick which channel (by name in panel)\n",
    "    channel_dropdown = widgets.Dropdown(\n",
    "        options=channel_names,\n",
    "        description='Channel:',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "\n",
    "    hp_threshold_text = widgets.FloatText(\n",
    "        value=5.0,\n",
    "        description='HP Thresh:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='160px')\n",
    "    )\n",
    "\n",
    "    hp_neighborhood_text = widgets.IntText(\n",
    "        value=3,\n",
    "        description='HP Neigh:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='160px')\n",
    "    )\n",
    "    \n",
    "    gauss_sigma_text = widgets.FloatText(\n",
    "        value=1.0,\n",
    "        description='Gauss σ:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='160px')\n",
    "    )\n",
    "\n",
    "    # Contrast slider: we pick a default range [0, 1]\n",
    "    # The user can drag the handles to set vmin/vmax for display.\n",
    "    contrast_slider = widgets.FloatRangeSlider(\n",
    "        value=[0.0, 1.0],\n",
    "        min=0.0,\n",
    "        max=1.0,\n",
    "        step=0.01,\n",
    "        description='Contrast',\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "\n",
    "    update_button = widgets.Button(\n",
    "        description=\"Update\",\n",
    "        button_style='success'\n",
    "    )\n",
    "\n",
    "    output_display = widgets.Output()\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 3. Define the callback for \"Update\" button\n",
    "    # --------------------------------------------------------------------------\n",
    "    def on_update_clicked(b):\n",
    "        with output_display:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            selected_image_name = image_dropdown.value\n",
    "            selected_channel_name = channel_dropdown.value\n",
    "            try:\n",
    "                channel_idx = channel_names.index(selected_channel_name)\n",
    "            except ValueError:\n",
    "                print(f\"Channel '{selected_channel_name}' not found in panel.\")\n",
    "                return\n",
    "\n",
    "            hp_thresh_val = hp_threshold_text.value\n",
    "            hp_neigh_val = hp_neighborhood_text.value\n",
    "            gauss_val = gauss_sigma_text.value\n",
    "            vmin, vmax = contrast_slider.value\n",
    "\n",
    "            # Build the path to the TIF file (expected one TIF in the subfolder)\n",
    "            subfolder_path = os.path.join(image_dir, selected_image_name)\n",
    "            tif_files = [\n",
    "                f for f in os.listdir(subfolder_path)\n",
    "                if f.lower().endswith('.tif') or f.lower().endswith('.tiff')\n",
    "            ]\n",
    "            if len(tif_files) != 1:\n",
    "                print(f\"Warning: expected 1 TIF in {subfolder_path}, found {len(tif_files)}.\")\n",
    "                return\n",
    "\n",
    "            tif_path = os.path.join(subfolder_path, tif_files[0])\n",
    "\n",
    "            # Read the stack\n",
    "            stack = tiff.imread(tif_path)\n",
    "            \n",
    "            # Check shape\n",
    "            if stack.shape[0] != num_channels:\n",
    "                print(\n",
    "                    f\"Warning: panel has {num_channels} channels, \"\n",
    "                    f\"but TIF has {stack.shape[0]} channels.\"\n",
    "                )\n",
    "            \n",
    "            # Extract the channel of interest\n",
    "            raw_channel = stack[channel_idx, :, :]\n",
    "\n",
    "            # Optionally crop\n",
    "            channel_for_processing = raw_channel\n",
    "            if crop is not None:\n",
    "                try:\n",
    "                    channel_for_processing = random_crop_2D(raw_channel, crop_size=crop)\n",
    "                except ValueError as e:\n",
    "                    print(str(e))\n",
    "                    return\n",
    "            \n",
    "            # Process the channel\n",
    "            processed_channel = process_channel(\n",
    "                channel_for_processing,\n",
    "                hp_threshold=hp_thresh_val,\n",
    "                hp_neighborhood=hp_neigh_val,\n",
    "                gauss_sigma=gauss_val\n",
    "            )\n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # Normalize each image to [0,1] for display\n",
    "            # This lets vmin/vmax in [0,1] do what we expect on the slider\n",
    "            # ------------------------------------------------------------------\n",
    "            def safe_normalize(img):\n",
    "                m = img.max()\n",
    "                if m < 1e-12:\n",
    "                    # Avoid divide-by-zero\n",
    "                    return np.zeros_like(img, dtype=np.float32)\n",
    "                return img.astype(np.float32) / m\n",
    "\n",
    "            raw_norm = safe_normalize(channel_for_processing)\n",
    "            proc_norm = safe_normalize(processed_channel)\n",
    "\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            # Raw\n",
    "            im0 = axes[0].imshow(raw_norm, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "            axes[0].set_title(f'Raw [{selected_image_name}] - {selected_channel_name}')\n",
    "            axes[0].axis('off')\n",
    "\n",
    "            # Processed\n",
    "            im1 = axes[1].imshow(proc_norm, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "            axes[1].set_title('Processed')\n",
    "            axes[1].axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    update_button.on_click(on_update_clicked)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 4. Layout the UI\n",
    "    # --------------------------------------------------------------------------\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([image_dropdown, channel_dropdown]),\n",
    "        widgets.HBox([hp_threshold_text, hp_neighborhood_text, gauss_sigma_text]),\n",
    "        contrast_slider,\n",
    "        update_button,\n",
    "        output_display\n",
    "    ])\n",
    "    \n",
    "    display(ui)\n",
    "\n",
    "    # Trigger an initial update to see something from the start\n",
    "    on_update_clicked(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyMComplete import CheckExtract\n",
    "\n",
    "CheckExtract(\n",
    "    rootdir = rootdir,\n",
    "    projdir =projdir\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional 2: Filter images\n",
    "\n",
    "This optional step allows you to filter your images by:\n",
    "\n",
    "- **Hot pixel filtering** (IF): Choose a threshold factor and a neighbourhood size in pixels. For each pixel, the value of a pixel is replaced by the average value of the neighbourhood if that pixel exceeds the threshold factor. This value can be tested using `CheckExtract()`.\n",
    "\n",
    "- **Gauss_blur** (IF): Choose a sigma value to also apply a gaussian blur, which if chosen correctly, can sometimes improve the contrast between the border of a cell and the background. This value can be tested using `CheckExtract()`.\n",
    "\n",
    "- **hpf** (IMC): Is the hotpixel filter applied to IMC data via the Bodenmiller function `create_analysis_stacks()`. The default value is 50. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Function: FilterImages()`\n",
    "\n",
    "<details><summary>Information</summary>\n",
    "\n",
    "```bash\n",
    "FilterImages(\n",
    "    rootdir = rootdir,\n",
    "    projdir = projdir,\n",
    "    panel_filename=\"panel.csv\",\n",
    "    fullstack = True, \n",
    "    format = \"if\", \n",
    "    hotpixel={\"threshold\":3,\"neighbourhood\":5}, \n",
    "    gauss_blur=1, \n",
    "    hpf=50,\n",
    "    extract_dir = \"analysis/1_image_out\", \n",
    "    clean_dir = \"analysis/2_cleaned\")\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Arguments:**  \n",
    "\n",
    "- `rootdir`: This directory is intended to store commonly used GitHub Repositories and other relevant resources.    \n",
    "\n",
    "- `projdir`: This directory is specific to individual projects.     \n",
    "\n",
    "- `panel_path`: This argument points to the `panel.csv`. The function will use the names in the `Target` column for the drop down options.    \n",
    "\n",
    "- `fullstack`: A logical value to choose whether to deposit all channels (`False`), or just the images that match `Full = 1` in `panel.csv` (`True`).\n",
    "\n",
    "- `format`: This argument strictly takes `if` or `imc` and processes the images accordingly.    \n",
    "\n",
    "- `hotpixel`: *If format == \"if\"*. Taken as two values, first the threshold factor and second the neighbourhood value. For each pixel, the value of a pixel is replaced by the average value of the neighbourhood if that pixel exceeds the threshold factor.    \n",
    "\n",
    "- `gauss_blur`: *If format == \"if\"*. The sigma value to apply to the images for blurring. Default is 1. \n",
    "\n",
    "- `hpf`: *If format == \"imc\"*. The hotpixel factor for IMC image filtering. \n",
    "\n",
    "- `extract_dir`: This argument specifies where the images are. The default is **\"analysis/1_image_out\"**.\n",
    "\n",
    "- `clean_dir`: Output directory. Default is **analysis/2_cleaned**\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Expected Outputs:**\n",
    "\n",
    "Images will be deposited into the specified clean_dir with the suffix *_cleaned*\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Packages:**   \n",
    "- pathlib\n",
    "- pandas\n",
    "- skimage\n",
    "- scipy.ndimage\n",
    "- skimage.filters\n",
    "- imcsegpipe\n",
    "- imcsegpipe.utils\n",
    "\n",
    "================================================================\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from scipy.ndimage import uniform_filter\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "def FilterImages(rootdir:str,\n",
    "                   projdir:str,\n",
    "                   panel_filename=\"panel.csv\",\n",
    "                   format:str, \n",
    "                   hotpixel=None, \n",
    "                   gauss_blur=None, \n",
    "                   fullstack = True, \n",
    "                   hpf=50,\n",
    "                   extract_dir = \"analysis/1_image_out\", \n",
    "                   clean_dir = \"analysis/2_cleaned\"):\n",
    "    \n",
    "    project_path = Path(rootdir) / projdir\n",
    "\n",
    "    images_dir = project_path / extract_dir\n",
    "    cleaned_dir = project_path / clean_dir\n",
    "    panel_path = project_path / panel_filename\n",
    "\n",
    "    panel = pd.read_csv(panel_path)\n",
    "\n",
    "    if format == \"if\":\n",
    "        def remove_hotpixels_threshold(img, threshold=5.0, neighborhood_size=3):\n",
    "            \"\"\"\n",
    "            Replace 'hot' pixels that are above (threshold * local_mean) with that local mean.\n",
    "            \"\"\"\n",
    "            img_float = img.astype(float)\n",
    "            local_mean = uniform_filter(img_float, size=neighborhood_size)\n",
    "            \n",
    "            # create mask of hot pixels\n",
    "            hot_mask = img_float > (threshold * local_mean)\n",
    "\n",
    "            cleaned_img = img_float.copy()\n",
    "            cleaned_img[hot_mask] = local_mean[hot_mask]\n",
    "\n",
    "            # Convert back to original dtype (e.g., uint16) if desired\n",
    "            return cleaned_img.astype(img.dtype)\n",
    "\n",
    "        def apply_gaussian_blur(img, sigma=1.0):\n",
    "                \"\"\"\n",
    "                Applies a Gaussian blur with a given sigma.\n",
    "                Returns the blurred image (preserving the original range).\n",
    "                \"\"\"\n",
    "                blurred = gaussian(img, sigma=sigma, preserve_range=True)\n",
    "                return blurred.astype(img.dtype)\n",
    "    \n",
    "        full_stack = []\n",
    "        for sample_dir in images_dir.iterdir():\n",
    "\n",
    "            # Skip hidden folders (for whatever reason they may exist)\n",
    "            if not sample_dir.is_dir() or sample_dir.name.startswith(\".\"):\n",
    "                continue\n",
    "\n",
    "            # We expect exactly one tiff. in the folder, check and then just read the first one.\n",
    "            tif_files = list(sample_dir.glob(\"*.tif*\"))\n",
    "            if len(tif_files) != 1:\n",
    "                raise ValueError(\n",
    "                    f\"Expected exactly 1 TIF in '{sample_dir.name}', found {len(tif_files)}.\"\n",
    "                )\n",
    "            single_tif = tif_files[0]\n",
    "            image = io.imread(str(single_tif))\n",
    "\n",
    "            # Check that the stack depth == number of rows in panel.csv\n",
    "            if image.shape[0] != len(panel):\n",
    "                raise ValueError(\n",
    "                    f\"Panel length is {len(panel)} but found `{image.shape[0]}` channels\"\n",
    "                    f\" in '{sample_dir.name}'.\"\n",
    "                )\n",
    "\n",
    "            # Process each channel in the stack\n",
    "            for idx in range(len(panel)):\n",
    "                channel = image[idx, :, :]\n",
    "\n",
    "                # 1) Hotpixel removal if threshold is not None\n",
    "                if hotpixel and hotpixel.get(\"threshold\") is not None:\n",
    "                    channel = remove_hotpixels_threshold(\n",
    "                        channel,\n",
    "                        threshold=hotpixel[\"threshold\"],\n",
    "                        neighborhood_size=hotpixel.get(\"neighborhood\", 3)\n",
    "                    )\n",
    "\n",
    "                # 2) Gaussian blur if gauss_blur is not None\n",
    "                if gauss_blur is not None:\n",
    "                    channel = apply_gaussian_blur(channel, sigma=gauss_blur)\n",
    "\n",
    "                if panel.loc[idx, \"Full\"] == 1:\n",
    "                    full_stack.append(img_as_uint(channel))\n",
    "                # Replace the channel in the stack\n",
    "                image[idx, :, :] = channel\n",
    "\n",
    "            cleaned_image_name = f\"{sample_dir.name}_cleaned.tiff\"\n",
    "            cleaned_image_path = cleaned_dir / cleaned_image_name\n",
    "            \n",
    "            if fullstack == True:\n",
    "                if len(full_stack) > 0:\n",
    "                    full_stack = np.stack(full_stack)\n",
    "                    io.imsave(str(full_tiff_path), full_stack)\n",
    "                else:\n",
    "                    print(f\"Warning: No 'Full' channels found for sample '{sample_dir.name}'.\")\n",
    "            else:\n",
    "                io.imsave(str(cleaned_image_path), image)\n",
    "\n",
    "\n",
    "\n",
    "    elif format == \"imc\":    \n",
    "\n",
    "        print(\"Generating Cleaned Images...\\n\")\n",
    "        print(\"Using hot pixel filter of \",hpf,\".\\n\")\n",
    "        import imcsegpipe\n",
    "        from imcsegpipe.utils import sort_channels_by_mass\n",
    "\n",
    "        for image_dir in images_dir.glob(\"[!.]*\"):\n",
    "            if image_dir.is_dir():\n",
    "                imcsegpipe.create_analysis_stacks(\n",
    "                    acquisition_dir=image_dir,\n",
    "                    analysis_dir=cleaned_dir,\n",
    "                    analysis_channels=sort_channels_by_mass(\n",
    "                        panel.loc[panel[\"Full\"] == 1, \"Conjugate\"].tolist()\n",
    "                    ),\n",
    "                    suffix=\"_cleaned\",\n",
    "                    hpf=hpf\n",
    "                )\n",
    "\n",
    "    elif format != \"if\" and format != \"imc\":\n",
    "        print(\"Format not specified. Choose 'imc' or 'if' specifically and run again.\\n\")\n",
    "\n",
    "filter_images(rootdir=rootdir,\n",
    "                   projdir=\"project\",\n",
    "                   format = 'if',\n",
    "                   panel_filename=\"panel.csv\",\n",
    "                   hotpixel=None,\n",
    "                   gauss_blur=None,\n",
    "                   hpf=50,\n",
    "                   extract_dir = \"analysis/1_image_out\",\n",
    "                   clean_dir = \"analysis/2_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyMComplete import FilterImages\n",
    "\n",
    "FilterImages(\n",
    "    rootdir = rootdir,\n",
    "    projdir = projdir,\n",
    "    panel_filename=\"panel.csv\",\n",
    "    format = \"if\", \n",
    "    hotpixel={\"threshold\":3,\"neighbourhood\":5}, \n",
    "    gauss_blur=1, \n",
    "    fullstack = True, \n",
    "    hpf=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional 3: Select Cropped regions for model training\n",
    "\n",
    "This function is also optional. This is a quick and easy way to select cropped regions for cell segmentation modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Function: CropSelector()`\n",
    "\n",
    "<details><summary>Information</summary>\n",
    "\n",
    "```bash\n",
    "CropSelector(\n",
    "        rootdir = \"rootdir\", \n",
    "        projdir = \"projdir\",\n",
    "        panel_path = \"panel.csv\",\n",
    "        image_path = \"image.csv\",\n",
    "        images_dir = \"analysis/2_cleaned\",\n",
    "        suffix  = \"_cleaned\")\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Arguments:**  \n",
    "\n",
    "- `rootdir`: This directory is intended to store commonly used GitHub Repositories and other relevant resources.    \n",
    "\n",
    "- `projdir`: This directory is specific to individual projects.     \n",
    "\n",
    "- `panel_path`: This argument points to the `panel.csv`. The function will use the names in the `Target` column for the drop down options.    \n",
    "\n",
    "- `image_path`: This argument points to the `iamge.csv`. Cropped coordinates for images are stored in the `Crop` column\n",
    "\n",
    "- `extract_dir`: This argument specifies where the images are. The default is **\"analysis/2_cleaned\"**.\n",
    "\n",
    "- `suffix`: specifies the suffix attached to the image names. The default images will be suffixed with **\"_cleaned\"**\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Expected Outputs:**\n",
    "\n",
    "A widget opens that allows the selection of the image, channel and a box to be drawn to create a cropped region appropriate for segmentation training. The coordinates are stored in image.csv. If crop coordinates are not specified, then \n",
    "\n",
    "================================================================\n",
    "\n",
    "**Packages:**   \n",
    "- os\n",
    "- numpy\n",
    "- pandas\n",
    "- tifffile \n",
    "- matplotlib.pyplot \n",
    "- ipywidgets \n",
    "- IPython.display \n",
    "- matplotlib.widgets \n",
    "\n",
    "================================================================\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib.widgets import RectangleSelector \n",
    "\n",
    "def CropSelector(\n",
    "        rootdir:str, \n",
    "        projdir:str,\n",
    "        panel_path = \"panel.csv\",\n",
    "        image_path = \"image.csv\",\n",
    "        images_dir = \"analysis/2_cleaned\",\n",
    "        suffix  = \"_cleaned\"):\n",
    "    \n",
    "    project_path = Path(rootdir) / projdir\n",
    "    im_dir =  project_path / images_dir\n",
    "    panel_path = project_path / panel_path\n",
    "    sample_csv_path = project_path / image_path\n",
    "\n",
    "    if not os.path.exists(panel_path):\n",
    "        raise FileNotFoundError(f\"Panel file not found: {panel_path}\")\n",
    "    panel = pd.read_csv(panel_path)\n",
    "\n",
    "    if not os.path.exists(sample_csv_path):\n",
    "        raise FileNotFoundError(f\"Image file not found: {sample_csv_path}\")\n",
    "    samples = pd.read_csv(sample_csv_path)\n",
    "\n",
    "    if \"Image\" not in samples.columns:\n",
    "        raise ValueError(\"image.csv must contain an 'Image' column.\")\n",
    "    if \"Target\" not in panel.columns:\n",
    "        raise ValueError(\"panel.csv must contain a 'Target' column for channel names.\")\n",
    "\n",
    "    # We'll use the \"Target\" column as channel names\n",
    "    channel_names = panel.loc[panel['Full'] == 1, 'Target'].tolist()\n",
    "    num_channels  = len(channel_names)\n",
    "\n",
    "    # Subfolders in 1_image_out\n",
    "    # Check if im_dir contains subdirectories or TIFF files directly\n",
    "    subdirs = [d for d in os.listdir(im_dir) if os.path.isdir(os.path.join(im_dir, d))]\n",
    "    tiff_files = []\n",
    "\n",
    "    if subdirs:\n",
    "        # If there are subdirectories, list TIFF files within each subdirectory\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(im_dir, subdir)\n",
    "            tiff_files.extend([\n",
    "                os.path.join(subdir, f) for f in os.listdir(subdir_path)\n",
    "                if f.endswith(\".tif\") or f.endswith(\".tiff\")\n",
    "            ])\n",
    "    else:\n",
    "        # If no subdirectories, list TIFF files directly in im_dir\n",
    "        tiff_files = [\n",
    "            f for f in os.listdir(im_dir)\n",
    "                if f.endswith(\".tif\") or f.endswith(\".tiff\")\n",
    "        ]\n",
    "\n",
    "    tiff_files.sort()\n",
    "    \n",
    "    # 2. Create Interactive Widgets\n",
    "    \n",
    "    image_dropdown = widgets.Dropdown(\n",
    "        options=tiff_files,\n",
    "        description='Image:',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "\n",
    "    channel_dropdown = widgets.Dropdown(\n",
    "        options=channel_names,\n",
    "        description='Channel:',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "\n",
    "    crop_button = widgets.Button(\n",
    "        description=\"Crop\",\n",
    "        button_style='success'\n",
    "    )\n",
    "    save_button = widgets.Button(\n",
    "        description=\"Save\",\n",
    "        button_style='info'\n",
    "    )\n",
    "\n",
    "    output_display = widgets.Output()\n",
    "\n",
    "    # We'll keep track of the figure, axes, selected ROI, and loaded data\n",
    "    # in these variables. We'll define them in the function's closure so we can\n",
    "    # access/update them in callbacks.\n",
    "    fig       = None\n",
    "    ax_left   = None\n",
    "    ax_right  = None\n",
    "    rect_sel  = None\n",
    "    roi       = {\"x\": 0, \"y\": 0, \"w\": 0, \"h\": 0}  # will store rectangle coords\n",
    "    current_channel_data = None      # the 2D channel image\n",
    "    cropped_data         = None      # the cropped region\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "    # 3. RectangleSelector callback\n",
    "    #--------------------------------------------------------------------------\n",
    "    def on_select(eclick, erelease):\n",
    "        \"\"\"\n",
    "        Called whenever the user finishes drawing or moving the rectangle.\n",
    "        eclick/erelease: mouse events with xdata, ydata in axes coords\n",
    "        \"\"\"\n",
    "        x1, y1 = eclick.xdata, eclick.ydata\n",
    "        x2, y2 = erelease.xdata, erelease.ydata\n",
    "\n",
    "        # Ensure we have integer coords\n",
    "        x_min, x_max = sorted([int(round(x1)), int(round(x2))])\n",
    "        y_min, y_max = sorted([int(round(y1)), int(round(y2))])\n",
    "        w = x_max - x_min\n",
    "        h = y_max - y_min\n",
    "\n",
    "        roi[\"x\"], roi[\"y\"], roi[\"w\"], roi[\"h\"] = x_min, y_min, w, h\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "    # 4. Function to load and display the selected channel\n",
    "    #--------------------------------------------------------------------------\n",
    "    def display_image(*args):\n",
    "        \"\"\"\n",
    "        Loads the selected image & channel, sets up the RectangleSelector on the left axis.\n",
    "        \"\"\"\n",
    "        nonlocal fig, ax_left, ax_right, rect_sel, current_channel_data, cropped_data\n",
    "        cropped_data = None  # reset\n",
    "        with output_display:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            selected_image_name = image_dropdown.value\n",
    "            selected_channel_name = channel_dropdown.value\n",
    "\n",
    "            # Convert that to a channel index\n",
    "            try:\n",
    "                channel_idx = channel_names.index(selected_channel_name)\n",
    "            except ValueError:\n",
    "                print(f\"Channel '{selected_channel_name}' not found in panel.\")\n",
    "                return\n",
    "\n",
    "            # Build the path to the TIF file (expected one TIF in the subfolder)\n",
    "            tif_path = os.path.join(im_dir, selected_image_name)\n",
    "\n",
    "\n",
    "            # Read the stack\n",
    "            stack = tiff.imread(tif_path)\n",
    "            if stack.shape[0] != num_channels:\n",
    "                print(\n",
    "                    f\"Warning: panel has {num_channels} channels, \"\n",
    "                    f\"but TIF has {stack.shape[0]} channels.\"\n",
    "                )\n",
    "\n",
    "            current_channel_data = stack[channel_idx, :, :]\n",
    "\n",
    "            # Create a new figure\n",
    "            fig, (ax_left, ax_right) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            fig.canvas.toolbar_visible = False  # optional: hide toolbar\n",
    "            fig.canvas.header_visible = False\n",
    "            fig.canvas.footer_visible = False\n",
    "\n",
    "            # Display the channel on the left\n",
    "            ax_left.imshow(current_channel_data, cmap='gray')\n",
    "            ax_left.set_title(f\"{selected_image_name} - {selected_channel_name}\")\n",
    "            ax_left.axis('off')\n",
    "\n",
    "            # The right side is blank initially\n",
    "            ax_right.imshow(np.zeros((10,10)), cmap='gray')\n",
    "            ax_right.set_title(\"Cropped Region\")\n",
    "            ax_right.axis('off')\n",
    "\n",
    "            # Create RectangleSelector for the left axis\n",
    "            rect_sel = RectangleSelector(\n",
    "                ax_left,\n",
    "                onselect=on_select,        # your callback function\n",
    "                useblit=False,\n",
    "                interactive=True,          # let the user move/resize the rectangle\n",
    "                button=[1],                # left mouse button\n",
    "                props=dict(\n",
    "                    facecolor='none',\n",
    "                    edgecolor='red',\n",
    "                    fill=False, alpha=1\n",
    "                )\n",
    "            )\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "    # Crop button callback\n",
    "    #--------------------------------------------------------------------------\n",
    "    def on_crop_clicked(b):\n",
    "        \"\"\"\n",
    "        Uses the ROI (roi dict) to crop the currently displayed channel, then\n",
    "        shows the result in ax_right.\n",
    "        \"\"\"\n",
    "        nonlocal cropped_data\n",
    "\n",
    "        if current_channel_data is None:\n",
    "            print(\"No image loaded yet.\")\n",
    "            return\n",
    "\n",
    "        x, y, w, h = roi[\"x\"], roi[\"y\"], roi[\"w\"], roi[\"h\"]\n",
    "        if w <= 0 or h <= 0:\n",
    "            print(\"Please draw a rectangle first.\")\n",
    "            return\n",
    "\n",
    "        # Perform the crop\n",
    "        cropped_data = current_channel_data[y:y+h, x:x+w]\n",
    "\n",
    "        with output_display:\n",
    "            clear_output(wait=False)  # keep the figure\n",
    "            # We'll re-draw the figure, focusing on the right axis\n",
    "            # The figure should already be defined\n",
    "            ax_right.clear()\n",
    "            ax_right.imshow(cropped_data, cmap='gray')\n",
    "            ax_right.set_title(f\"Cropped: x={x}, y={y}, w={w}, h={h}\")\n",
    "            ax_right.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "    # Save button callback\n",
    "    #--------------------------------------------------------------------------\n",
    "    def on_save_clicked(b):\n",
    "        \"\"\"\n",
    "        Saves the crop coords as \"x_y_w_h\" in image.csv for the row\n",
    "        where samples['Image'] equals the selected image.\n",
    "        \"\"\"\n",
    "        selected_image_name = image_dropdown.value\n",
    "        imagename = os.path.splitext(selected_image_name)[0].replace(suffix, \"\")\n",
    "\n",
    "        x, y, w, h = roi[\"x\"], roi[\"y\"], roi[\"w\"], roi[\"h\"]\n",
    "\n",
    "        if w <= 0 or h <= 0:\n",
    "            print(\"No valid crop selected. Did you draw a rectangle?\")\n",
    "            return\n",
    "        coords_str = f\"{x}_{y}_{w}_{h}_manual\"\n",
    "\n",
    "        # Find the row in samples where 'Image' = selected_image_name\n",
    "        # If multiple rows match, will update all... \n",
    "        mask = (samples[\"Image\"] == imagename)\n",
    "        if not mask.any():\n",
    "            print(f\"No row in image.csv with Image == '{imagename}'.\")\n",
    "            return\n",
    "        \n",
    "        #Check if Crop exists as a column\n",
    "        if \"Crop\" not in samples.columns:\n",
    "            samples[\"Crop\"] = np.nan\n",
    "        samples[\"Crop\"] = samples[\"Crop\"].astype(\"string\")\n",
    "\n",
    "        samples.loc[mask, \"Crop\"] = coords_str\n",
    "\n",
    "        # Save back to CSV\n",
    "        samples.to_csv(sample_csv_path, index=False)\n",
    "        print(f\"Saved coords '{coords_str}' for image '{imagename}' into image.csv.\")\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "    # 7. Wire up callbacks\n",
    "    #--------------------------------------------------------------------------\n",
    "    # Show or re-show the image whenever the user changes either dropdown\n",
    "    image_dropdown.observe(display_image, names='value')\n",
    "    channel_dropdown.observe(display_image, names='value')\n",
    "\n",
    "    # Or whenever the function first runs\n",
    "    # we can do an initial display after the UI is built.\n",
    "\n",
    "    crop_button.on_click(on_crop_clicked)\n",
    "    save_button.on_click(on_save_clicked)\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "    # 8. Layout the UI\n",
    "    #--------------------------------------------------------------------------\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([image_dropdown, channel_dropdown]),\n",
    "        widgets.HBox([crop_button, save_button]),\n",
    "        output_display\n",
    "    ])\n",
    "    \n",
    "    display(ui)\n",
    "\n",
    "    # Trigger an initial display\n",
    "    display_image()\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "CropSelector(\n",
    "    rootdir = rootdir, \n",
    "    projdir = projdir,\n",
    "    panel_path = \"panel.csv\",\n",
    "    image_path = \"image.csv\",\n",
    "    images_dir = \"analysis/2_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "CropSelector(\n",
    "    rootdir = rootdir, \n",
    "    projdir = projdir,\n",
    "    panel_path = \"panel.csv\",\n",
    "    image_path = \"image.csv\",\n",
    "    images_dir = \"analysis/2_cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Prepare the images for cell segmentation model training\n",
    "\n",
    "This function takes images from the 2_cleaned/ folder and deposits images into two folders: \n",
    "- 3a_cellpose_crop: used to train a segmentation model.\n",
    "- 3b_cellpose_full: used to generate cell masks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Function: PrepCellpose()`\n",
    "\n",
    "<details><summary>Information</summary>\n",
    "\n",
    "```bash\n",
    "PrepCellpose(\n",
    "    rootdir, \n",
    "    projdir, \n",
    "    nucleus=\"DNA\", \n",
    "    resolution=1, \n",
    "    crop_size=200,\n",
    "    panel_dir = \"panel.csv\",\n",
    "    images_dir = \"image.csv\",\n",
    "    im_from = \"analysis/2_cleaned\", \n",
    "    suffix = \"_cleaned\",\n",
    "    fullstack = True,\n",
    "    crop_to = \"analysis/3_segmentation/3a_cellpose_crop\",\n",
    "    full_to = \"analysis/3_segmentation/3b_cellpose_full\"\n",
    ")\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Arguments:**  \n",
    "- `rootdir`: This directory is intended to store commonly used GitHub Repositories and other relevant resources.  \n",
    "\n",
    "- `projdir`: This directory is specific to individual projects. \n",
    "\n",
    "- `nucleus`: The nuclear stain that corresponds with the name listed in the *Target* column of `panel.csv`.\n",
    "\n",
    "- `resolution`: The user can specify the resolution of their images which is used for generating *x* µm cropped regions.\n",
    "\n",
    "- `crop_size`: The user can specify the size in **µm** of cropped regions they'd like to randomly generate.\n",
    "\n",
    "- `panel_dir`: The directory of the `panel.csv` file relative to `rootdir/projdir`.\n",
    "\n",
    "- `images_dir`: The directory of the `image.csv` file relative to `rootdir/projdir`.\n",
    "\n",
    "- `im_from`: The directory images to prepare for use in cell segmentation relative to `rootdir/projdir`.\n",
    "\n",
    "- `suffix`: The suffix appended to the image name. For example, images in 2_cleaned are appended with \"_cleaned\"\n",
    "\n",
    "- `fullstack`: Specify whether the image has been cut of non-essential channels or not. For example, `True` specifies that the images in the `im_from` directory are stacks containing channels where `Full == 1` in `panel.csv`. `False` specifies that the images need to be subset based on `Full == 1` in `panel.csv`.\n",
    "\n",
    "- `crop_to`: The directory to output the cropped images relative to `rootdir/projdir`.\n",
    "\n",
    "- `full_to`: The directory to output the full sized images relative to `rootdir/projdir`.\n",
    "\n",
    "- `out_suffix`: Specifies the suffix attached to the output images. Default is *\"_CpSeg\"*\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Expected Outputs:**\n",
    "\n",
    "```text\n",
    "Segmentation Targets: [....]\n",
    "Image1: random-cropped at (x=31, y=67, size=200).\"\n",
    "Image2: used manual crop 65_101_189_210\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Packages:**   \n",
    "- os\n",
    "- random\n",
    "- tifffile\n",
    "- numpy\n",
    "- pandas\n",
    "- skimage\n",
    "\n",
    "================================================================\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import exposure, img_as_uint\n",
    "\n",
    "def PrepCellpose(\n",
    "    rootdir, \n",
    "    projdir, \n",
    "    nucleus=\"DNA\", \n",
    "    resolution=1, \n",
    "    crop_size=200,\n",
    "    panel_dir=\"panel.csv\",\n",
    "    images_dir=\"image.csv\",\n",
    "    im_from=\"analysis/2_cleaned\", \n",
    "    suffix=\"_cleaned\",\n",
    "    fullstack=True,\n",
    "    crop_to=\"analysis/3_segmentation/3a_cellpose_crop\",\n",
    "    full_to=\"analysis/3_segmentation/3b_cellpose_full\",\n",
    "    out_suffix = \"_CpSeg\"\n",
    "): \n",
    "    # Define directories\n",
    "    panel_file = os.path.join(rootdir, projdir, panel_dir)\n",
    "    image_csv = os.path.join(rootdir, projdir, images_dir) \n",
    "    dir_images = os.path.join(rootdir, projdir, im_from)\n",
    "    crop_output = os.path.join(rootdir, projdir, crop_to)\n",
    "    im_output = os.path.join(rootdir, projdir, full_to)\n",
    "\n",
    "    # Read panel.csv\n",
    "    panel = pd.read_csv(panel_file)\n",
    "\n",
    "    # Read image.csv and check for required column\n",
    "    df_image = pd.read_csv(image_csv)\n",
    "    if \"Crop\" not in df_image.columns:\n",
    "        raise ValueError(\"image.csv must contain a 'Crop' column.\\n\")\n",
    "\n",
    "    # Get list of images to process\n",
    "    image_list = df_image[\"Image\"].tolist()\n",
    "\n",
    "    # Convert user-specified crop_size (in resolution units) to pixels\n",
    "    crop_size_px = int(crop_size * resolution)\n",
    "\n",
    "    # Process each image\n",
    "    for image_file in image_list:\n",
    "        # Build the expected filename using the suffix\n",
    "        candidate1 = os.path.join(dir_images, f\"{image_file}{suffix}.tiff\")\n",
    "        candidate2 = os.path.join(dir_images, f\"{image_file}{suffix}.tif\")\n",
    "        if os.path.exists(candidate1):\n",
    "            full_image_path = candidate1\n",
    "        elif os.path.exists(candidate2):\n",
    "            full_image_path = candidate2\n",
    "        else:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Error: File '{image_file}{suffix}.tiff' (or .tif) not found in {dir_images}. \"\n",
    "                \"Please check your suffix and naming.\\n\"\n",
    "            )\n",
    "\n",
    "        # Read the image stack from file\n",
    "        image_stack = tifffile.imread(full_image_path)\n",
    "\n",
    "        # Process based on the fullstack flag\n",
    "        if fullstack:\n",
    "            # Expect the stack to have only the channels where Full == 1\n",
    "            expected_channels = int(panel[\"Full\"].sum())\n",
    "            if image_stack.shape[0] != expected_channels:\n",
    "                raise ValueError(\n",
    "                    f\"Error: For fullstack==True, expected {expected_channels} channels (per panel.csv 'Full' column) \"\n",
    "                    f\"but found {image_stack.shape[0]} in image '{image_file}{suffix}'.\\n\"\n",
    "                )\n",
    "            # Create a sub-panel for the full channels\n",
    "            full_panel = panel[panel[\"Full\"] == 1].reset_index(drop=True)\n",
    "        else:\n",
    "            # Expect the stack to have all channels (length == panel length)\n",
    "            if image_stack.shape[0] != len(panel):\n",
    "                raise ValueError(\n",
    "                    f\"Error: For fullstack==False, expected image stack length equal to panel length ({len(panel)}) \"\n",
    "                    f\"but found {image_stack.shape[0]} channels in image '{image_file}{suffix}'.\\n\"\n",
    "                )\n",
    "            # Subset the stack to only the channels where Full == 1\n",
    "            full_indices = panel.index[panel[\"Full\"] == 1].tolist()\n",
    "            image_stack = image_stack[full_indices, :, :]\n",
    "            full_panel = panel.loc[panel[\"Full\"] == 1].reset_index(drop=True)\n",
    "\n",
    "        # Determine segmentation targets from the full_panel (only for channels flagged for segmentation)\n",
    "        segmentation_targets = full_panel.loc[full_panel[\"Segment\"] == 1, \"Target\"].tolist()\n",
    "        print(\"Segmentation Targets for image\", image_file, \":\", segmentation_targets,\".\\n\")\n",
    "\n",
    "        # Find the index of the nucleus channel within the segmentation targets\n",
    "        dna_index = [i for i, target in enumerate(segmentation_targets) if target == nucleus]\n",
    "        if not dna_index:\n",
    "            raise ValueError(\n",
    "                f\"Error: DNA channel '{nucleus}' not found in segmentation targets for image '{image_file}{suffix}'.\\n\"\n",
    "            )\n",
    "        # Normalise only the channels flagged for segmentation (Segment == 1)\n",
    "        normalized_stack = []\n",
    "        for i in range(image_stack.shape[0]):\n",
    "            # Check if the current channel should be segmented according to panel\n",
    "            if full_panel.iloc[i][\"Segment\"] == 1:\n",
    "                channel = image_stack[i, :, :]\n",
    "                normalized = exposure.rescale_intensity(channel, in_range='image', out_range=(0, 1))\n",
    "                normalized_stack.append(img_as_uint(normalized))\n",
    "        if normalized_stack:\n",
    "            normalized_stack = np.stack(normalized_stack)  # shape: (C_segment, H, W)\n",
    "        else:\n",
    "            raise ValueError(\"No channels with Segment==1 found in panel.\")\n",
    "        \n",
    "        # Identify the DNA channel from the normalised stack\n",
    "        dna_chan = normalized_stack[dna_index[0]]\n",
    "        # Remove the DNA channel(s) to compute the surface mask from the remaining channels\n",
    "        for idx in sorted(dna_index, reverse=True):\n",
    "            normalized_stack = np.delete(normalized_stack, idx, axis=0)\n",
    "        surface_mask = np.mean(normalized_stack, axis=0).astype(np.uint16)\n",
    "\n",
    "        # Build the composite stack with three channels: [empty, surface, DNA]\n",
    "        empty_channel = np.zeros_like(dna_chan, dtype=np.uint16)\n",
    "        composite_stack = np.stack([empty_channel, surface_mask, dna_chan])\n",
    "\n",
    "        # Save the full composite image\n",
    "        im_output_path = os.path.join(im_output, f\"{image_file}{out_suffix}.tiff\")\n",
    "        tifffile.imwrite(im_output_path, composite_stack)\n",
    "\n",
    "        # Determine cropping parameters\n",
    "        user_crop_str = df_image.loc[df_image[\"Image\"] == image_file, \"Crop\"].values[0]  # e.g., \"50_100_400_300\" or <NA>\n",
    "        _, height, width = composite_stack.shape\n",
    "\n",
    "        if isinstance(user_crop_str, str) and user_crop_str.lower() != \"nan\":\n",
    "            try:\n",
    "                parts = user_crop_str.split(\"_\")\n",
    "                if len(parts) < 4:\n",
    "                    raise ValueError(\"Not enough crop parameters provided.\\n\")\n",
    "                x, y, w, h = map(int, parts[:4])\n",
    "                # Validate that the provided crop coordinates are within image bounds\n",
    "                if (x + w <= width) and (y + h <= height) and (w > 0) and (h > 0):\n",
    "                    cropped = composite_stack[:, y:y+h, x:x+w]\n",
    "                    crop_output_path = os.path.join(crop_output, f\"{image_file}{out_suffix}.tiff\")\n",
    "                    tifffile.imwrite(crop_output_path, cropped)\n",
    "                    print(f\"{image_file}: used manual crop {x}_{y}_{w}_{h}.\\n\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"{image_file}: user crop coordinates out of bounds => performing random crop.\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"{image_file}: error parsing Crop='{user_crop_str}' => performing random crop. {e}\\n\")\n",
    "\n",
    "        # If no valid user crop is provided, perform a random crop\n",
    "        if width < crop_size_px or height < crop_size_px:\n",
    "            # If the image is smaller than the desired crop size, save it without cropping.\n",
    "            crop_output_path = os.path.join(crop_output, f\"{image_file}{out_suffix}.tiff\")\n",
    "            tifffile.imwrite(crop_output_path, composite_stack)\n",
    "            print(f\"Image {image_file} is smaller than {crop_size_px} px => saved without cropping.\\n\")\n",
    "            continue\n",
    "\n",
    "        workable_x = width - crop_size_px\n",
    "        workable_y = height - crop_size_px\n",
    "        rand_x = random.randint(0, workable_x)\n",
    "        rand_y = random.randint(0, workable_y)\n",
    "        cropped = composite_stack[:, rand_y:rand_y + crop_size_px, rand_x:rand_x + crop_size_px]\n",
    "        \n",
    "        coords_str = f\"{rand_x}_{rand_y}_{crop_size_px}_{crop_size_px}_random\"\n",
    "        df_image.loc[df_image[\"Image\"] == image_file, \"Crop\"] = coords_str\n",
    "\n",
    "        crop_output_path = os.path.join(crop_output, f\"{image_file}{out_suffix}.tiff\")\n",
    "        tifffile.imwrite(crop_output_path, cropped)\n",
    "        print(f\"{image_file}: random-cropped at (x={rand_x}, y={rand_y}, size={crop_size_px})\\n.\")\n",
    "\n",
    "    # Write the updated image.csv back to disk\n",
    "    df_image.to_csv(os.path.join(rootdir, projdir, images_dir), index=False)\n",
    "    print(\"\\nDone!\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyMComplete import PrepCellpose\n",
    "\n",
    "PrepCellpose(\n",
    "    rootdir = rootdir, \n",
    "    projdir=projdir, \n",
    "    nucleus=\"191Ir_191Ir_DNA1\", \n",
    "    resolution=1, \n",
    "    crop_size=200,\n",
    "    panel_dir=\"panel.csv\",\n",
    "    images_dir=\"image.csv\",\n",
    "    im_from=\"analysis/2_cleaned\", \n",
    "    suffix=\"_full\",\n",
    "    fullstack=True,\n",
    "    crop_to=\"analysis/3_segmentation/3a_cellpose\",\n",
    "    full_to=\"analysis/3_segmentation/3b_cellpose\",\n",
    "    out_suffix = \"_full\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional 3: Registration with CV2\n",
    "\n",
    "Image registration might be necessary to improve cell segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Function: RegisterImages()`\n",
    "\n",
    "You'll need two directories: \n",
    "- static images (registered to) and      \n",
    "- moving images (to register).\n",
    "\n",
    "Your directory may look like this:\n",
    "\n",
    "```text\n",
    "rootdir/projdir\n",
    "├── analysis\n",
    "│     └── 1_image_out\n",
    "│     └── 2_cleaned\n",
    "│            └── imagename1_cleaned.tiff\n",
    "│            └── imagename2_cleaned.tiff\n",
    "│            └── ...\n",
    "│     └── 3_segmentation\n",
    "│     └── ...\n",
    "├── analysis\n",
    "├── Immunofluorescent\n",
    "│     └── imagename1_IF.tiff\n",
    "│     └── imagename2_IF.tiff\n",
    "│     └── ...\n",
    "├── panel.csv\n",
    "├── panel_reg.csv\n",
    "```\n",
    "\n",
    "- `imagename1_cleaned.tiff` will be cleaned images that are *n*-sized stacks that match Full==1 in `panel.csv`  \n",
    "- `imagename1_IF.tiff` will be images to register that are *n*-sized stacks that match Full==1 in `panel_IF.csv` **Note**: This *can* be single layer images, and this just needs to be reflected in the `panel_IF.csv`    \n",
    "- `panel_IF.csv` should contain UNIQUE channel names to `panel.csv` - so that you don't get instances of duplicates. E.g. you could have CD3 in your IMC stack and CD3 in your IF stack - just append anything from `panel_IF.csv` with a sufflix like *CD3_IF*\n",
    "\n",
    "<details><summary>Information</summary>\n",
    "\n",
    "```bash\n",
    "RegisterImages(\n",
    "    rootdir = rootdir, \n",
    "    projdir = projdir, \n",
    "    static_dir = \"analysis/2_cleaned\", \n",
    "    static_channel = \"DNA\", \n",
    "    static_suffix = \"_cleaned\", \n",
    "    static_panel_dir = \"panel.csv\", \n",
    "    moving_dir = \"IF\", \n",
    "    moving_channel = \"DAPI\", \n",
    "    moving_suffix = \"_IF\",\n",
    "    moving_panel_dir = \"panel_reg.csv\",\n",
    "    out_dir = \"analysis/2b_registered\", \n",
    "    out_dir_suffix = \"_registered\",\n",
    "    combine = True\n",
    ")\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Arguments:**  \n",
    "- `rootdir`: This directory is intended to store commonly used GitHub Repositories and other relevant resources.  \n",
    "\n",
    "- `projdir`: This directory is specific to individual projects. \n",
    "\n",
    "- `static_dir`: This directory specifies the images that you want to use as the static image for registration\n",
    "\n",
    "- `static_channel`: This correlates to a name listed in the *Target* column in `panel.csv` that is used for registration - likely a DNA channel\n",
    "\n",
    "- `static_suffix`: This specifies the suffix attached to the *imagename* - for example, in **2_cleaned**, the default suffix is *_cleaned*. \n",
    "\n",
    "- `static_panel_dir`: Points to the panel that corresponds to the static images. The default is `panel.csv`\n",
    "\n",
    "- `moving_dir`: This directory specifies the images that you want to register to the static images. \n",
    "\n",
    "- `moving_channel`: This correlates to a name listed in the *Target* column in `panel.csv` that is used for registration - likely a DAPI channel\n",
    "\n",
    "- `moving_suffix`: This specifies the suffix attached to the *imagename* - for example, in **2_cleaned**, the default suffix is *_cleaned*. \n",
    "\n",
    "- `moving_panel_dir`: Points to the panel that corresponds to the moving images. The default is `panel.csv`\n",
    "\n",
    "- `out_dir`: Directory to output images relative to rootdir/projdir. Default is *\"analysis/2b_registered\"*\n",
    "\n",
    "- `out_dir_suffix`: The suffix to add to output images. Default is *\"_reg\"*.\n",
    "\n",
    "- `combine`: This argument specifies whether you want to output the transformed moving image by itself, or append the moving image stack to the static image stack. For example, 4 channel IF gets appended to the 30 channel IMC after registering DAPI to DNA. The output image would be a 34 channel `image_reg.tiff`.\n",
    "\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Packages:**   \n",
    "- os    \n",
    "- cv2   \n",
    "- numpy \n",
    "- pandas    \n",
    "- tifffile  \n",
    "- matplotlib.pyplot \n",
    "- matplotlib.widgets    \n",
    "- IPython.display   \n",
    "- ipywidgets    \n",
    "\n",
    "================================================================\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "\n",
    "def RegisterImages(rootdir, \n",
    "                   projdir, \n",
    "                   static_dir, \n",
    "                   static_channel, \n",
    "                   static_suffix, \n",
    "                   moving_dir, \n",
    "                   moving_channel = \"DAPI\", \n",
    "                   moving_suffix,\n",
    "                   out_dir = \"analysis/2b_registered\", \n",
    "                   out_dir_suffix = \"_reg\",\n",
    "                   static_panel_dir = \"panel.csv\", \n",
    "                   moving_panel_dir = \"panel_IF.csv\",\n",
    "                   combine=False):\n",
    "    \"\"\"\n",
    "    Creates an interactive UI to register a static image (e.g. IMC DNA) with a moving image (e.g. IF DAPI).\n",
    "    If combine==True, then when saving, the transform is applied to all slices of the moving image stack,\n",
    "    and the resulting transformed moving stack is appended to the full static image stack.\n",
    "    A combined panel CSV is also generated by concatenating the raw static and moving panel CSVs.\n",
    "    \"\"\"\n",
    "    # --- Helper functions for contrast adjustment and tinting ---\n",
    "    def adjust_contrast_range(image, contrast_range):\n",
    "        image_norm = image.astype(np.float32) / 255.0\n",
    "        low, high = contrast_range\n",
    "        if high - low < 1e-6:\n",
    "            return image.copy()\n",
    "        stretched = np.clip((image_norm - low) / (high - low), 0, 1)\n",
    "        return (stretched * 255).astype(np.uint8)\n",
    "\n",
    "    def tint_blue(image):\n",
    "        return np.stack([np.zeros_like(image), np.zeros_like(image), image], axis=-1)\n",
    "\n",
    "    def tint_yellow(image):\n",
    "        return np.stack([image, image, np.zeros_like(image)], axis=-1)\n",
    "\n",
    "    # --- Load panel CSV and get channel index ---\n",
    "    def load_panel(panel_csv_path, channel_name):\n",
    "        panel = pd.read_csv(panel_csv_path)\n",
    "        panel_full = panel[panel[\"Full\"]==1].reset_index(drop=True)\n",
    "        matches = panel_full.index[panel_full[\"Target\"]==channel_name].tolist()\n",
    "        if not matches:\n",
    "            raise ValueError(f\"Channel '{channel_name}' not found in panel {panel_csv_path}.\")\n",
    "        return panel_full, matches[0]\n",
    "    \n",
    "    # --- List image files and extract base names ---\n",
    "    def list_images(image_dir, suffix):\n",
    "        valid_ext = (\".tif\", \".tiff\")\n",
    "        files = [f for f in os.listdir(image_dir) if f.endswith(valid_ext) and f.find(suffix) != -1]\n",
    "        base_names = {}\n",
    "        for f in files:\n",
    "            for ext in valid_ext:\n",
    "                if f.endswith(suffix + ext):\n",
    "                    name = f[:-len(suffix + ext)]\n",
    "                    base_names[name] = f\n",
    "                    break\n",
    "        return base_names\n",
    "\n",
    "    # --- Load an image stack and select the channel slice ---\n",
    "    def load_channel_image(image_dir, base_name, suffix, panel_csv, channel_name):\n",
    "        for ext in [\".tif\", \".tiff\"]:\n",
    "            candidate = os.path.join(image_dir, f\"{base_name}{suffix}{ext}\")\n",
    "            if os.path.exists(candidate):\n",
    "                file_path = candidate\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Image file for {base_name}{suffix} not found in {image_dir}.\")\n",
    "        img_stack = tifffile.imread(file_path)\n",
    "        panel_full, chan_idx = load_panel(os.path.join(rootdir, projdir, panel_csv), channel_name)\n",
    "        if img_stack.ndim == 3:\n",
    "            if chan_idx >= img_stack.shape[0]:\n",
    "                raise ValueError(f\"Channel index {chan_idx} out of bounds for image stack with {img_stack.shape[0]} slices.\")\n",
    "            img = img_stack[chan_idx, :, :]\n",
    "        else:\n",
    "            img = img_stack.copy()\n",
    "        if img.dtype != np.uint8:\n",
    "            img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "        return img\n",
    "\n",
    "    # --- Helper function to load full image stack ---\n",
    "    def load_full_stack(image_dir, base_name, suffix):\n",
    "        for ext in [\".tif\", \".tiff\"]:\n",
    "            candidate = os.path.join(image_dir, f\"{base_name}{suffix}{ext}\")\n",
    "            if os.path.exists(candidate):\n",
    "                return tifffile.imread(candidate)\n",
    "        raise FileNotFoundError(f\"Full image stack for {base_name}{suffix} not found in {image_dir}.\")\n",
    "\n",
    "    # --- Prepare image file lists and dropdown menus ---\n",
    "    static_images = list_images(os.path.join(rootdir, projdir, static_dir), static_suffix)\n",
    "    moving_images = list_images(os.path.join(rootdir, projdir, moving_dir), moving_suffix)\n",
    "    \n",
    "    static_dropdown = widgets.Dropdown(options=sorted(static_images.keys()), description=\"Static:\")\n",
    "    moving_dropdown = widgets.Dropdown(options=sorted(moving_images.keys()), description=\"Moving:\")\n",
    "\n",
    "    # --- Global variables ---\n",
    "    static_img_orig = None\n",
    "    moving_img_orig = None\n",
    "    global_overlay = None\n",
    "    global_static  = None\n",
    "    global_aligned = None\n",
    "    global_fig = None\n",
    "    global_ax_left = None\n",
    "    global_ax_right = None\n",
    "    ROI = {\"x\": 0, \"y\": 0, \"w\": 0, \"h\": 0}\n",
    "    rect_sel = None\n",
    "    saved_path = None\n",
    "    # Store the computed transformation matrix and dimensions\n",
    "    transformation_matrix = None\n",
    "    global_dims = None\n",
    "    registration_metrics = {}\n",
    "\n",
    "    # --- Widgets for adjustable parameters ---\n",
    "    static_contrast_slider = widgets.FloatRangeSlider(\n",
    "        value=[0.0, 1.0], min=0.0, max=1.0, step=0.01,\n",
    "        description='Static Contrast:',\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    moving_contrast_slider = widgets.FloatRangeSlider(\n",
    "        value=[0.0, 1.0], min=0.0, max=1.0, step=0.01,\n",
    "        description='Moving Contrast:',\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    ratio_threshold_slider = widgets.FloatSlider(value=0.92, min=0.80, max=0.98, step=0.01, description='Ratio Thresh:')\n",
    "    ransac_threshold_slider  = widgets.IntSlider(value=25, min=5, max=50, step=1, description='RANSAC Thresh:')\n",
    "    sift_sigma_slider        = widgets.FloatSlider(value=1.6, min=1.0, max=3.0, step=0.1, description='SIFT Sigma:')\n",
    "    hist_eq_checkbox         = widgets.Checkbox(value=True, description='Histogram Equalisation')\n",
    "\n",
    "    update_button = widgets.Button(description=\"Update Registration\", button_style='success')\n",
    "    crop_button   = widgets.Button(description=\"Crop\", button_style='warning')\n",
    "    save_button   = widgets.Button(description=\"Save Registered IF\", button_style='info')\n",
    "    output_folder_text = widgets.Text(\n",
    "        value=os.path.join(rootdir, projdir, out_dir),\n",
    "        description=\"Output Folder:\",\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "    \n",
    "    fig_out = widgets.Output()\n",
    "\n",
    "    # --- Load images based on dropdown selection ---\n",
    "    def load_images_from_selection(change=None):\n",
    "        nonlocal static_img_orig, moving_img_orig\n",
    "        base_static = static_dropdown.value\n",
    "        base_moving = moving_dropdown.value\n",
    "        static_img_orig = load_channel_image(os.path.join(rootdir, projdir, static_dir),\n",
    "                                             base_static, static_suffix,\n",
    "                                             static_panel_dir, static_channel)\n",
    "        moving_img_orig = load_channel_image(os.path.join(rootdir, projdir, moving_dir),\n",
    "                                             base_moving, moving_suffix,\n",
    "                                             moving_panel_dir, moving_channel)\n",
    "    \n",
    "    load_images_from_selection()\n",
    "    static_dropdown.observe(load_images_from_selection, names='value')\n",
    "    moving_dropdown.observe(load_images_from_selection, names='value')\n",
    "\n",
    "    # --- Registration and display function ---\n",
    "    def update_registration(b):\n",
    "        nonlocal global_overlay, global_static, global_aligned, global_fig, global_ax_left, global_ax_right, rect_sel, ROI, transformation_matrix, global_dims, registration_metrics\n",
    "        with fig_out:\n",
    "            clear_output(wait=True)\n",
    "            static_range = static_contrast_slider.value\n",
    "            moving_range = moving_contrast_slider.value\n",
    "            ratio_thresh    = ratio_threshold_slider.value\n",
    "            ransac_thresh   = ransac_threshold_slider.value\n",
    "            sift_sigma      = sift_sigma_slider.value\n",
    "            use_hist_eq     = hist_eq_checkbox.value\n",
    "\n",
    "            if use_hist_eq:\n",
    "                static_img = cv2.equalizeHist(static_img_orig)\n",
    "                moving_img = cv2.equalizeHist(moving_img_orig)\n",
    "            else:\n",
    "                static_img = static_img_orig.copy()\n",
    "                moving_img = moving_img_orig.copy()\n",
    "            static_img = adjust_contrast_range(static_img, static_range)\n",
    "            moving_img = adjust_contrast_range(moving_img, moving_range)\n",
    "\n",
    "            h_static, w_static = static_img.shape\n",
    "            h_moving, w_moving = moving_img.shape\n",
    "            global_dims = (w_static, h_static)\n",
    "            if (h_moving, w_moving) != (h_static, w_static):\n",
    "                scale_x = w_moving / w_static\n",
    "                scale_y = h_moving / h_static\n",
    "                moving_img_small = cv2.resize(moving_img, (w_static, h_static), interpolation=cv2.INTER_AREA)\n",
    "            else:\n",
    "                scale_x = scale_y = 1.0\n",
    "                moving_img_small = moving_img.copy()\n",
    "\n",
    "            sift = cv2.SIFT_create(nOctaveLayers=3, sigma=sift_sigma)\n",
    "            kp_static, des_static = sift.detectAndCompute(static_img, None)\n",
    "            kp_moving_small, des_moving_small = sift.detectAndCompute(moving_img_small, None)\n",
    "\n",
    "            bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "            matches = bf.knnMatch(des_static, des_moving_small, k=2) if (des_static is not None and des_moving_small is not None) else []\n",
    "            good_matches = [m for m, n in matches if m.distance < ratio_thresh * n.distance] if matches else []\n",
    "\n",
    "            if len(good_matches) >= 3:\n",
    "                pts_static = np.float32([kp_static[m.queryIdx].pt for m in good_matches]).reshape(-1,2)\n",
    "                pts_moving_small = np.float32([kp_moving_small[m.trainIdx].pt for m in good_matches]).reshape(-1,2)\n",
    "                M_small, inliers = cv2.estimateAffine2D(pts_moving_small, pts_static, None, cv2.RANSAC, ransac_thresh, 2000, 0.99, 10)\n",
    "                if M_small is not None:\n",
    "                    M = M_small.copy()\n",
    "                    M[0,0] /= scale_x\n",
    "                    M[0,1] /= scale_y\n",
    "                    M[1,0] /= scale_x\n",
    "                    M[1,1] /= scale_y\n",
    "                    transformation_matrix = M.copy()\n",
    "                    rotation_rad = np.arctan2(M[1,0], M[0,0])\n",
    "                    rotation_deg = np.degrees(rotation_rad)\n",
    "                    scale_x_val = np.sqrt(M[0,0]**2 + M[1,0]**2)\n",
    "                    scale_y_val = np.sqrt(M[0,1]**2 + M[1,1]**2)\n",
    "                    translation_x = M[0,2]\n",
    "                    translation_y = M[1,2]\n",
    "                    registration_metrics['Rotation (deg)'] = rotation_deg\n",
    "                    registration_metrics['Scale X'] = scale_x_val\n",
    "                    registration_metrics['Scale Y'] = scale_y_val\n",
    "                    registration_metrics['Translation X'] = translation_x\n",
    "                    registration_metrics['Translation Y'] = translation_y\n",
    "\n",
    "                    aligned_moving = cv2.warpAffine(moving_img, M, (w_static, h_static), flags=cv2.INTER_LINEAR)\n",
    "                else:\n",
    "                    aligned_moving = cv2.resize(moving_img, (w_static, h_static))\n",
    "            else:\n",
    "                aligned_moving = cv2.resize(moving_img, (w_static, h_static))\n",
    "\n",
    "            global_aligned = aligned_moving.copy()\n",
    "            blue_static   = tint_blue(static_img)\n",
    "            yellow_aligned = tint_yellow(aligned_moving)\n",
    "            overlay = cv2.addWeighted(blue_static, 0.5, yellow_aligned, 0.5, 0)\n",
    "\n",
    "            global_overlay = overlay\n",
    "            global_static  = static_img.copy()\n",
    "            ROI[\"x\"] = ROI[\"y\"] = ROI[\"w\"] = ROI[\"h\"] = 0\n",
    "\n",
    "            global_fig, (global_ax_left, global_ax_right) = plt.subplots(1, 2, figsize=(12,6))\n",
    "            global_ax_left.imshow(static_img, cmap='gray')\n",
    "            global_ax_left.set_title(\"Static Image — Draw ROI here\")\n",
    "            global_ax_left.axis('off')\n",
    "            global_ax_right.imshow(overlay)\n",
    "            global_ax_right.set_title(\"Registration Output (Overlay)\")\n",
    "            global_ax_right.axis('off')\n",
    "            rect_sel = RectangleSelector(\n",
    "                global_ax_left,\n",
    "                on_select,\n",
    "                useblit=False,\n",
    "                interactive=True,\n",
    "                button=[1],\n",
    "                props=dict(facecolor='none', edgecolor='red', fill=False, alpha=1)\n",
    "            )\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def on_select(eclick, erelease):\n",
    "        x1, y1 = eclick.xdata, eclick.ydata\n",
    "        x2, y2 = erelease.xdata, erelease.ydata\n",
    "        x_min, x_max = sorted([int(round(x1)), int(round(x2))])\n",
    "        y_min, y_max = sorted([int(round(y1)), int(round(y2))])\n",
    "        ROI[\"x\"] = x_min\n",
    "        ROI[\"y\"] = y_min\n",
    "        ROI[\"w\"] = x_max - x_min\n",
    "        ROI[\"h\"] = y_max - y_min\n",
    "\n",
    "    def crop_callback(b):\n",
    "        nonlocal global_ax_right\n",
    "        if ROI[\"w\"] <= 0 or ROI[\"h\"] <= 0:\n",
    "            with fig_out:\n",
    "                print(\"Please draw a rectangle on the left image first.\")\n",
    "            return\n",
    "        cropped = global_overlay[ROI[\"y\"]:ROI[\"y\"]+ROI[\"h\"], ROI[\"x\"]:ROI[\"x\"]+ROI[\"w\"]]\n",
    "        global_ax_right.clear()\n",
    "        global_ax_right.imshow(cropped)\n",
    "        global_ax_right.set_title(f\"Cropped Region (x={ROI['x']}, y={ROI['y']}, w={ROI['w']}, h={ROI['h']})\")\n",
    "        global_ax_right.axis('off')\n",
    "        global_fig.canvas.draw_idle()\n",
    "\n",
    "    def save_callback(b):\n",
    "        nonlocal saved_path\n",
    "        out_folder = output_folder_text.value.strip()\n",
    "        if not out_folder:\n",
    "            with fig_out:\n",
    "                print(\"Please specify a valid output folder.\")\n",
    "            return\n",
    "        if not os.path.exists(out_folder):\n",
    "            os.makedirs(out_folder)\n",
    "        base_static = static_dropdown.value\n",
    "        filename = f\"{base_static}{static_suffix}{out_dir_suffix}.tiff\"\n",
    "        saved_path = os.path.join(out_folder, filename)\n",
    "        cv2.imwrite(saved_path, global_aligned)\n",
    "        settings = {\n",
    "            \"Static Contrast\": static_contrast_slider.value,\n",
    "            \"Moving Contrast\": moving_contrast_slider.value,\n",
    "            \"Ratio Threshold\": ratio_threshold_slider.value,\n",
    "            \"RANSAC Threshold\": ransac_threshold_slider.value,\n",
    "            \"SIFT Sigma\": sift_sigma_slider.value,\n",
    "            \"Histogram Equalisation\": hist_eq_checkbox.value,\n",
    "            \"ROI\": ROI\n",
    "        }\n",
    "        settings.update(registration_metrics)\n",
    "        options_path = os.path.join(out_folder, f\"{base_static}{static_suffix}{out_dir_suffix}_options.csv\")\n",
    "        pd.DataFrame([settings]).to_csv(options_path, index=False)\n",
    "        with fig_out:\n",
    "            print(\"Registered image saved to:\", saved_path)\n",
    "            print(\"Options saved to:\", options_path)\n",
    "        \n",
    "        # If combine==True, perform full-stack registration and panel concatenation.\n",
    "        if combine and transformation_matrix is not None:\n",
    "            # Load full stacks\n",
    "            static_stack = load_full_stack(os.path.join(rootdir, projdir, static_dir), base_static, static_suffix)\n",
    "            moving_stack = load_full_stack(os.path.join(rootdir, projdir, moving_dir), moving_dropdown.value, moving_suffix)\n",
    "            w_static, h_static = global_dims\n",
    "            transformed_moving_stack = []\n",
    "            for i in range(moving_stack.shape[0]):\n",
    "                ch_img = moving_stack[i, :, :]\n",
    "                transformed = cv2.warpAffine(ch_img, transformation_matrix, (w_static, h_static), flags=cv2.INTER_LINEAR)\n",
    "                transformed_moving_stack.append(transformed)\n",
    "            transformed_moving_stack = np.stack(transformed_moving_stack)\n",
    "            combined_stack = np.concatenate([static_stack, transformed_moving_stack], axis=0)\n",
    "            combined_filename = f\"{base_static}{static_suffix}{out_dir_suffix}_combined.tiff\"\n",
    "            combined_path = os.path.join(out_folder, combined_filename)\n",
    "            tifffile.imwrite(combined_path, combined_stack)\n",
    "            # Create panel_combined by concatenating the raw CSVs\n",
    "            panel_static = pd.read_csv(os.path.join(rootdir, projdir, static_panel_dir))\n",
    "            panel_moving = pd.read_csv(os.path.join(rootdir, projdir, moving_panel_dir))\n",
    "            panel_combined = pd.concat([panel_static, panel_moving], ignore_index=True)\n",
    "            static_panel_dir_full = os.path.join(rootdir, projdir, os.path.dirname(static_panel_dir))\n",
    "            panel_combined_path = os.path.join(static_panel_dir_full, \"panel_combined.csv\")\n",
    "            panel_combined.to_csv(panel_combined_path, index=False)\n",
    "            with fig_out:\n",
    "                print(\"Combined image stack saved to:\", combined_path)\n",
    "                print(\"Combined panel saved to:\", panel_combined_path)\n",
    "\n",
    "    update_button.on_click(update_registration)\n",
    "    crop_button.on_click(crop_callback)\n",
    "    save_button.on_click(save_callback)\n",
    "\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([static_dropdown, moving_dropdown]),\n",
    "        widgets.HBox([static_contrast_slider, moving_contrast_slider]),\n",
    "        widgets.HBox([ratio_threshold_slider, ransac_threshold_slider, sift_sigma_slider]),\n",
    "        hist_eq_checkbox,\n",
    "        widgets.HBox([update_button, crop_button, save_button]),\n",
    "        output_folder_text,\n",
    "        fig_out\n",
    "    ])\n",
    "    display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from PyMComplete import RegisterImages\n",
    "\n",
    "RegisterImages(rootdir = rootdir, \n",
    "               projdir = projdir, \n",
    "               static_dir = \"analysis/2_cleaned\", \n",
    "               static_channel = \"DNA\", \n",
    "               static_suffix=\"_cleaned\", \n",
    "               static_panel_dir = \"panel.csv\", \n",
    "               moving_dir = \"raw/IFImages\", \n",
    "               moving_channel = \"DAPI\", \n",
    "               moving_suffix=\"_IF\",\n",
    "               moving_panel_dir = \"panel_IF.csv\",\n",
    "               out_dir=\"analysis/2b_registered\", \n",
    "               out_dir_suffix=\"_reg\",\n",
    "               combine=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, you would use prep_cellpose() using the DAPI stain instead of DNA. \n",
    "\n",
    "You'll train the images on IMC-surface + IF-nuclear stains\n",
    "\n",
    "**If you do not have an IF image for every IMC image** - you'll need to have two `2_cleaned folders` and two `image.csv`. In this scenario, you would have a folder of images that match IF images. You would train on this first. Then, you would have all unregistered images and output all of these with DNA and, using the same model, train on all DNA images. Then, batch segment on the DNA images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train the segmentation model\n",
    "\n",
    "In this workflow, we use the cellpose segmentation workflow. *This is technically an optional step*, but we've found that no generalised model works universally. Once you open cellpose, there's a dropdown menu option under Models > Training Instructions that you can follow. I outline the process below: \n",
    "\n",
    "a. **Run *cellpose* using**    \n",
    "```bash\n",
    "python -m cellpose\n",
    "```\n",
    "\n",
    "b. **Drag an image from 2a_cellpose_crop into the cellpose window.**\n",
    "\n",
    "c. **Run a generalised segmentation model and adjust the available arguments until you're satisfied with an initial segmentation, such as:**\n",
    "\n",
    "> *Cell probability threshold (cellprob threshold):* Sets the minimum confidence for a pixel to be assigned to a cell.\n",
    "> **Increasing**: Leads to more conservative segmentation—only high-confidence pixels are included, which can reduce false positives but may miss faint or borderline cells. **Decreasing**: Results in a more inclusive segmentation, capturing more potential cell pixels at the risk of incorporating noise or false positives.\n",
    "\n",
    "> *Flow threshold:* Determines the required strength of the flow field (i.e. directional gradients) used to outline cell boundaries.\n",
    "> **Increasing**: Demands a stronger, clearer flow signal for segmentation, which may avoid oversegmentation but might miss cells with subtle boundaries. **Decreasing**: Lowers the barrier for segmentation based on flow, potentially detecting cells with weak signals but risking merging or oversegmentation of adjacent cells.\n",
    "\n",
    "> *Norm percentiles:* Defines the intensity range (by setting lower and upper percentile bounds) for image normalisation, affecting contrast and dynamic range.\n",
    "> **Increasing the upper percentile or decreasing the lower percentile**: Expands the dynamic range, enhancing contrast in brighter regions but possibly exaggerating noise. **Decreasing the upper percentile or increasing the lower percentile**: Compresses the dynamic range, which can reduce noise and improve overall uniformity, though it might diminish contrast for dimmer cells. \n",
    "\n",
    "d. **Adjust the cell masks and cmd/ctrl-S to save:**   \n",
    ">  hold cmd/ctrl and click to remove a mask     \n",
    "> right click and drag to create a new outline\n",
    "\n",
    "e. **Press cmd/ctrl-T to train the model:** Choose your pretrained model and adjust the options available. Cellpose will open the next image with the segmentation mask generated by the model.\n",
    "\n",
    "f. **Repeat d-e as many times as necessary, and until you're satisfied with the model outcomes.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m cellpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Batch segment the images and generate cell masks\n",
    "\n",
    "Once you've generated a segmentation model, or you intend to use a generalised model, you can use `BatchSegment()` to create mask tiff files. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Function: BatchSegment()`\n",
    "\n",
    "There are two options:\n",
    "- use a segmentation model trained on the cropped images in cellpose    \n",
    "- use a segmentation model built-in to cellpose, such as *'cyto3', 'cyto2', 'cyto', 'nuclei', 'tissuenet_cp3', 'livecell_cp3', 'yeast_PhC_cp3','yeast_BF_cp3', 'bact_phase_cp3', 'bact_fluor_cp3', 'deepbacs_cp3', 'cyto2_cp3'*.    \n",
    "\n",
    "If you want to outsource segmentation and want to continue to using this pipeline, reimport images to the `mask_to` folder. The default is *\"analysis/3_segmentation/3c_cellpose_mask\"*\n",
    "\n",
    "<details><summary>Information</summary>\n",
    "\n",
    "```bash\n",
    "BatchSegment(\n",
    "    rootdir,\n",
    "    projdir,\n",
    "    model = None, \n",
    "    builtin_model = None, \n",
    "    channels = [2, 3],\n",
    "    cell_diameter,\n",
    "    flow_threshold,\n",
    "    cellprob_threshold,\n",
    "    model_dir =\"analysis/3_segmentation/3a_cellpose_crop/models\",\n",
    "    full_from = \"analysis/3_segmentation/3b_cellpose_full\",\n",
    "    mask_to = \"analysis/3_segmentation/3c_cellpose_mask\",\n",
    "    suffix = \"_mask\"\n",
    ")\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Arguments:**  \n",
    "- `rootdir`: This directory is intended to store commonly used GitHub Repositories and other relevant resources.  \n",
    "\n",
    "- `projdir`: This directory is specific to individual projects. \n",
    "\n",
    "- `model`: The name of your segmentation model. If you choose to use a builtin model, leave this empty.\n",
    "\n",
    "- `builtin_model`: If you choose to use a built-in model, specify the name of the model. Current options are: *'cyto3', 'cyto2', 'cyto', 'nuclei', 'tissuenet_cp3', 'livecell_cp3', 'yeast_PhC_cp3','yeast_BF_cp3', 'bact_phase_cp3', 'bact_fluor_cp3', 'deepbacs_cp3', 'cyto2_cp3'*. \n",
    "\n",
    "- `channels`: The channels to use for segmentation. The default is [2,3] which specifies [green(surface),blue(nucleus)]\n",
    "\n",
    "- `cell_diameter`: A value taken from cellpose for the expected cell diameter. \n",
    "\n",
    "- `flow_threshold`: A value taken from cellpose for the flow_threshold.  \n",
    "\n",
    "- `cellprob_threshold`: A value taken from cellpose for the cellprob_threshold. \n",
    "\n",
    "- `model_dir`: Directory to the model folder. Default is *\"analysis/3_segmentation/3a_cellpose_crop/models\"*\n",
    "\n",
    "- `full_from`: Directory to the images folder. Default is *\"analysis/3_segmentation/3a_cellpose_crop/full_from\"*\n",
    "\n",
    "- `mask_to`: Where the masks are deposited.\n",
    "\n",
    "- `suffix`: The appended suffix to each image. The default is *\"_mask\"*\n",
    "\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Packages:**   \n",
    "- os    \n",
    "- skimage.io   \n",
    "- cellpose\n",
    "- cellpose.io\n",
    "- pathlib\n",
    "- tifffile  \n",
    "\n",
    "================================================================\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.io\n",
    "from cellpose import models\n",
    "from cellpose.io import logger_setup\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "\n",
    "def BatchSegment(\n",
    "        rootdir,\n",
    "        projdir,\n",
    "        model = None, \n",
    "        builtin_model = None, \n",
    "        channels = [2, 3],\n",
    "        cell_diameter: int,\n",
    "        flow_threshold: int,\n",
    "        cellprob_threshold: int,\n",
    "        model_dir =\"analysis/3_segmentation/3a_cellpose_crop/models\",\n",
    "        full_from = \"analysis/3_segmentation/3b_cellpose_full\",\n",
    "        mask_to = \"analysis/3_segmentation/3c_cellpose_mask\",\n",
    "        suffix = \"_mask\"\n",
    "        ):\n",
    "    \n",
    "    # Define Cellpose model\n",
    "    if model is not None: \n",
    "        model_path = os.path.join(rootdir, projdir,model_dir, model)\n",
    "        if os.path.exists(model_path):\n",
    "            print(\"Choosing \", model_path)\n",
    "            model = models.CellposeModel(pretrained_model=model_path)\n",
    "\n",
    "        else:\n",
    "            print(\"Model path does not exist. Exiting...\")\n",
    "            print(model_path)\n",
    "            return\n",
    "        \n",
    "    elif model is None and builtin_model is not None: \n",
    "        if builtin_model in ['cyto3', 'cyto2', 'cyto', 'nuclei']:\n",
    "            print(\"Choosing \", builtin_model)\n",
    "            model = models.Cellpose(model_type=builtin_model)\n",
    "        elif builtin_model in ['tissuenet_cp3', 'livecell_cp3', 'yeast_PhC_cp3','yeast_BF_cp3', 'bact_phase_cp3', 'bact_fluor_cp3', 'deepbacs_cp3', 'cyto2_cp3']:\n",
    "            model=models.CellposeModel(model_type='tissuenet_cp3')\n",
    "        else: \n",
    "            print(\"'\",builtin_model, \"' not available as a built in model.\")\n",
    "            print(\"Choose: cyto, cyto2, cyto3, nuclei, tissuenet_cp3, livecell_cp3, yeast_PhC_cp3,yeast_BF_cp3, bact_phase_cp3, bact_fluor_cp3, deepbacs_cp3, or cyto2_cp3.\")\n",
    "            return\n",
    "\n",
    "    # Set and create directories\n",
    "    analysis = Path(os.path.join(rootdir, projdir))\n",
    "    image_dir = analysis / full_from\n",
    "    mask_dir = analysis / mask_to\n",
    "\n",
    "    # Call logger_setup to have output of cellpose written\n",
    "    logger_setup()\n",
    "\n",
    "    # Get list of image files\n",
    "    files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(\".tiff\")] \n",
    "    imgs = [tifffile.imread(f) for f in files]\n",
    "\n",
    "    # Run segmentation\n",
    "    masks, flows, styles  = model.eval(imgs, diameter=cell_diameter, flow_threshold=flow_threshold, cellprob_threshold=cellprob_threshold, channels=channels)\n",
    "\n",
    "    # Save mask images\n",
    "    for idx, mask in enumerate(masks):\n",
    "        original_path = Path(files[idx])\n",
    "        new_path = mask_dir / (original_path.stem + suffix +\".tif\")\n",
    "        skimage.io.imsave(new_path, mask)\n",
    "\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyMComplete import BatchSegment\n",
    "\n",
    "BatchSegment(\n",
    "        rootdir = rootdir,\n",
    "        projdir = projdir,\n",
    "        model = None, \n",
    "        builtin_model = None, \n",
    "        channels = [2, 3],\n",
    "        cell_diameter = 14.3,\n",
    "        flow_threshold = 0,\n",
    "        cellprob_threshold = 0,\n",
    "        model_dir =\"analysis/3_segmentation/3a_cellpose_crop/models\",\n",
    "        full_from = \"analysis/3_segmentation/3b_cellpose_full\",\n",
    "        mask_to = \"analysis/3_segmentation/3c_cellpose_mask\",\n",
    "        suffix = \"_mask\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. PyProfiler\n",
    "\n",
    "PyProfiler does exactly what cellprofiler does, but without the need for an additional application. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Function: PyProfiler()`\n",
    "\n",
    "There are two options:\n",
    "- use a segmentation model trained on the cropped images in cellpose    \n",
    "- use a segmentation model built-in to cellpose, such as *'cyto3', 'cyto2', 'cyto', 'nuclei', 'tissuenet_cp3', 'livecell_cp3', 'yeast_PhC_cp3','yeast_BF_cp3', 'bact_phase_cp3', 'bact_fluor_cp3', 'deepbacs_cp3', 'cyto2_cp3'*.    \n",
    "\n",
    "If you want to outsource segmentation and want to continue to using this pipeline, reimport images to the `mask_to` folder. The default is *\"analysis/3_segmentation/3c_cellpose_mask\"*\n",
    "\n",
    "<details><summary>Information</summary>\n",
    "\n",
    "```bash\n",
    "pyprofiler(\n",
    "    rootdir, \n",
    "    projdir, \n",
    "    mean = 1, \n",
    "    shape = 1, \n",
    "    geometry = 1, \n",
    "    compartment = 1,\n",
    "    compartment_measure = \"mean\",\n",
    "    neighbours = 0,\n",
    "    boundary_contacts = False \n",
    "    panel_path = \"panel.csv\",\n",
    "    mask_dir =  \"analysis/3_segmentation/3e_cellpose_mask\",\n",
    "    image_dir = \"analysis/3_segmentation/3a_fullstack\", \n",
    "    compartment_dir =  \"analysis/3_segmentation/3f_compartments\", \n",
    "    out_dir = \"analysis/4_pyprofiler_output/cell.csv\",\n",
    "    geom_out_dir = \"analysis/4_pyprofiler_output/geom.csv\", \n",
    "    mask_suffix = \"_mask\",\n",
    "    image_suffix = \"_full\",\n",
    "    comp_suffix = \"_compartment\",\n",
    "\n",
    ")\n",
    "```\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Arguments:**  \n",
    "\n",
    "- `rootdir`: This directory is intended to store commonly used GitHub Repositories and other relevant resources.  \n",
    "\n",
    "- `projdir`: This directory is specific to individual projects. \n",
    "\n",
    "- `mean`: A logic value to collect the mean intensities of the cell mask in the fullstack images.  \n",
    "\n",
    "- `shape`: A logic value to collect additional shape metrics: area and eccentricity. \n",
    "\n",
    "- `geometry`: A logic value that specifies whether you want to collect cell geometry features which can be used to reconstruct the shape of the cell masks. **Note**: This can add about 50% extra processing time. \n",
    "\n",
    "- `compartment`: A logic value that specifies whether you want to collect information from compartment masks.\n",
    "\n",
    "- `compartment_measure`: The method for collecting information from a compartment mask. The options include:  \n",
    "    \n",
    "    - `\"centroid\"` will take the exact value at the centroid location of the cell\n",
    "\n",
    "    - `\"mean\"` will take the mean pixel value of the cell mask pixels on the compartment image.\n",
    "\n",
    "    - `\"mode\"` will take the most frequent value of the cell mask pixels on the compartment image.\n",
    "\n",
    "- `neighbours`: A numeric value to determine the nearest *n* neighbouring cells and their distances. The output is additional columns (`nearest_neighbour` and `nearest_neighbours_dist`)to the cell.csv with values such as: nearestCell1_nearestCell2...nearestCell*n*, and distToCell1_distToCell2...distToCell*n*. Default is 0. **Note**: This does **not** increase the processing time. \n",
    "\n",
    "- `boundary_contacts`: A logic value that determines the number of pixels that border on other cells. The output is an additional column to the cell.csv with values such as \"0x20_5x12\" or \"cellIDxpixels_cellIDxpixels\". Default is 1. **Note**: This increases the time it takes to generate the cell.csv file by about 3x. \n",
    "\n",
    "- `panel_path`: Path to panel.csv.\n",
    "\n",
    "- `mask_dir`: Directory of the mask images.\n",
    "\n",
    "- `image_dir`: Directory of the fullstack images\n",
    "\n",
    "- `compartment_dir`: Parent directory for the compartment folders. \n",
    "\n",
    "- `out_dir`: Output file for cell features.\n",
    "\n",
    "- `geom_out_dir`: Output file for the csv containing geometry information. \n",
    "\n",
    "- `mask_suffix`: The suffix for masks. The default is \"_mask\"\n",
    "\n",
    "- `image_suffix`: The suffix for fullstack images. The default is \"_full\"\n",
    "\n",
    "- `comp_suffix`: The suffix for compartment masks. The default is \"_compartment\"\n",
    "\n",
    "================================================================\n",
    "\n",
    "**Packages:**   \n",
    "- os    \n",
    "- time\n",
    "- numpy\n",
    "- pandas\n",
    "- tifffile\n",
    "- skiimage.measure\n",
    "- torch\n",
    "- scipy.ndimage\n",
    "- scipy.spatial.distance\n",
    "- collections\n",
    "\n",
    "================================================================\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tifffile import imread\n",
    "from skimage.measure import find_contours\n",
    "import torch\n",
    "from scipy.ndimage import binary_dilation, generate_binary_structure\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def PyProfiler(rootdir = \"\", \n",
    "               projdir = \"\", \n",
    "               mean = 1, \n",
    "               shape = 1, \n",
    "               geometry = 1, \n",
    "               compartment = 1,\n",
    "               compartment_measure = \"mean\",\n",
    "               panel_path = \"panel.csv\",\n",
    "               mask_dir =  \"analysis/3_segmentation/3e_cellpose_mask\",\n",
    "               image_dir = \"analysis/3_segmentation/3a_fullstack\", \n",
    "               compartment_dir =  \"analysis/3_segmentation/3f_compartments\", \n",
    "               out_dir = \"analysis/4_pyprofiler_output/cell.csv\",\n",
    "               geom_out_dir = \"analysis/4_pyprofiler_output/geom.csv\", \n",
    "               mask_suffix = \"_mask\",\n",
    "               image_suffix = \"_full\",\n",
    "               comp_suffix = \"_compartment\",\n",
    "               neighbours=0,           # Number of nearest neighbours to find\n",
    "               boundary_contacts=False # If True, store boundary contact breakdown in a single column\n",
    "               ):\n",
    "\n",
    "    # Check for CUDA availability\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Directories\n",
    "    masks_dir = os.path.join(rootdir, projdir, mask_dir)\n",
    "    stacks_dir = os.path.join(rootdir, projdir, image_dir)\n",
    "    compartments_dir = os.path.join(rootdir, projdir, compartment_dir)\n",
    "\n",
    "    # Get list of mask files (.tif or .tiff)\n",
    "    mask_files = [f for f in os.listdir(masks_dir) if f.endswith(('.tif', '.tiff'))]\n",
    "    image_names = [os.path.splitext(f)[0].replace(mask_suffix, \"\") for f in mask_files]\n",
    "\n",
    "    # Identify compartments if applicable\n",
    "    if compartment:\n",
    "        compartment_folders = [\n",
    "            f for f in os.listdir(compartments_dir) \n",
    "            if os.path.isdir(os.path.join(compartments_dir, f))\n",
    "        ]\n",
    "        if not compartment_folders:\n",
    "            print(\"No folders found in the compartments directory. Disabling compartment processing.\")\n",
    "            compartment = 0\n",
    "        else:\n",
    "            compartment_masks = {}\n",
    "            for folder in compartment_folders:\n",
    "                folder_path = os.path.join(compartments_dir, folder)\n",
    "                compartment_masks[folder] = {\n",
    "                    f: os.path.join(folder_path, f)\n",
    "                    for f in os.listdir(folder_path)\n",
    "                    if f.endswith(('.tif', '.tiff'))\n",
    "                }\n",
    "\n",
    "    # Prepare for overall results\n",
    "    all_results = []\n",
    "    all_geom_results = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Process each image\n",
    "    # ----------------------------------------------------------\n",
    "    for name in image_names:\n",
    "        print(f\"Processing {name}...\")\n",
    "\n",
    "        # Resolve actual mask path\n",
    "        mask_path_tif = os.path.join(masks_dir, f\"{name}{mask_suffix}.tif\")\n",
    "        mask_path_tiff = os.path.join(masks_dir, f\"{name}{mask_suffix}.tiff\")\n",
    "        if os.path.exists(mask_path_tif):\n",
    "            mask_path = mask_path_tif\n",
    "        elif os.path.exists(mask_path_tiff):\n",
    "            mask_path = mask_path_tiff\n",
    "        else:\n",
    "            print(f\"No mask file found with .tif or .tiff extension for {name}\")\n",
    "            continue\n",
    "\n",
    "        # Resolve actual stack path\n",
    "        stack_path_tif = os.path.join(stacks_dir, f\"{name}{image_suffix}.tif\")\n",
    "        stack_path_tiff = os.path.join(stacks_dir, f\"{name}{image_suffix}.tiff\")\n",
    "        if os.path.exists(stack_path_tif):\n",
    "            stack_path = stack_path_tif\n",
    "        elif os.path.exists(stack_path_tiff):\n",
    "            stack_path = stack_path_tiff\n",
    "        else:\n",
    "            print(f\"No stack file found with .tif or .tiff extension for {name}\")\n",
    "            continue\n",
    "\n",
    "        # Read images\n",
    "        cell_mask = imread(mask_path)           \n",
    "        fluorescence_stack = imread(stack_path) \n",
    "\n",
    "        # Convert to PyTorch\n",
    "        cell_mask_tensor = torch.tensor(cell_mask, device=device, dtype=torch.int32)\n",
    "        fluorescence_stack_tensor = torch.tensor(fluorescence_stack, device=device, dtype=torch.float32)\n",
    "\n",
    "        # If boundary contacts are needed, keep a CPU copy\n",
    "        cell_mask_cpu = cell_mask_tensor.cpu().numpy() if boundary_contacts else None\n",
    "\n",
    "        # Load panel\n",
    "        panel_path_full = os.path.join(rootdir, projdir, panel_path)\n",
    "        panel = pd.read_csv(panel_path_full)\n",
    "        selected_markers = panel[panel['Full'] == 1].reset_index(drop=True)\n",
    "        selected_indices = range(len(selected_markers)) \n",
    "        selected_names = selected_markers['Target'].values\n",
    "\n",
    "        # Extract unique CellIDs\n",
    "        cell_ids = torch.unique(cell_mask_tensor).cpu().numpy()\n",
    "\n",
    "        # Prepare results\n",
    "        results = []\n",
    "        geom_results = []\n",
    "\n",
    "        # Compartment data\n",
    "        compartment_data = {}\n",
    "        if compartment:\n",
    "            for comp_name, comp_files in compartment_masks.items():\n",
    "                comp_file_tif = comp_files.get(f\"{name}{comp_suffix}.tif\")\n",
    "                comp_file_tiff = comp_files.get(f\"{name}{comp_suffix}.tiff\")\n",
    "                comp_file = comp_file_tif if comp_file_tif else comp_file_tiff\n",
    "                if comp_file:\n",
    "                    compartment_data[comp_name] = torch.tensor(\n",
    "                        imread(comp_file),\n",
    "                        device=device, \n",
    "                        dtype=torch.float32\n",
    "                    )\n",
    "\n",
    "        # ----------------------------------------\n",
    "        # Process each cell\n",
    "        # ----------------------------------------\n",
    "        for cell_id in cell_ids:\n",
    "            cell_region = (cell_mask_tensor == cell_id)\n",
    "            cell_data = {\n",
    "                \"Image\": name,\n",
    "                \"CellID\": int(cell_id)\n",
    "            }\n",
    "\n",
    "            if shape:\n",
    "                # Area\n",
    "                cell_data[\"Area\"] = int(torch.sum(cell_region).item())\n",
    "\n",
    "                # Centroid\n",
    "                if torch.any(cell_region):\n",
    "                    indices = torch.nonzero(cell_region, as_tuple=True)\n",
    "                    centroid_y = torch.mean(indices[0].float()).item()\n",
    "                    centroid_x = torch.mean(indices[1].float()).item()\n",
    "                else:\n",
    "                    centroid_y, centroid_x = np.nan, np.nan\n",
    "\n",
    "                cell_data[\"X\"] = centroid_x\n",
    "                cell_data[\"Y\"] = centroid_y\n",
    "\n",
    "                # Eccentricity\n",
    "                bbox_indices = torch.nonzero(cell_region)\n",
    "                if bbox_indices.shape[0] > 0:\n",
    "                    height = bbox_indices[:, 0].max().item() - bbox_indices[:, 0].min().item() + 1\n",
    "                    width  = bbox_indices[:, 1].max().item() - bbox_indices[:, 1].min().item() + 1\n",
    "                    cell_data[\"Eccentricity\"] = height / width if width != 0 else np.nan\n",
    "                else:\n",
    "                    cell_data[\"Eccentricity\"] = np.nan\n",
    "\n",
    "                # --------------------------------------------------\n",
    "                # BOUNDARY CONTACT CALCULATIONS (Renamed & Combined)\n",
    "                # --------------------------------------------------\n",
    "                if boundary_contacts and cell_id != 0:\n",
    "                    # Identify boundary pixels\n",
    "                    cell_region_cpu = (cell_mask_cpu == cell_id)\n",
    "                    structure = generate_binary_structure(2, 1)\n",
    "                    dilated   = binary_dilation(cell_region_cpu, structure=structure)\n",
    "                    boundary  = np.logical_xor(cell_region_cpu, dilated)\n",
    "                    boundary_coords = np.argwhere(boundary)\n",
    "\n",
    "                    # Keep a breakdown of how many boundary pixels touch each neighbour ID\n",
    "                    neighbour_counts = defaultdict(int)\n",
    "\n",
    "                    # Loop over each boundary pixel\n",
    "                    for (yy, xx) in boundary_coords:\n",
    "                        # Gather all distinct neighbour IDs (besides the cell itself)\n",
    "                        neighbours_found = set()\n",
    "                        # Check 8 neighbours\n",
    "                        for ny in [yy-1, yy, yy+1]:\n",
    "                            for nx in [xx-1, xx, xx+1]:\n",
    "                                if (ny, nx) != (yy, xx):\n",
    "                                    if (0 <= ny < cell_mask_cpu.shape[0]) and (0 <= nx < cell_mask_cpu.shape[1]):\n",
    "                                        neighbour_id = cell_mask_cpu[ny, nx]\n",
    "                                        if neighbour_id != cell_id:  \n",
    "                                            neighbours_found.add(neighbour_id)\n",
    "                        \n",
    "                        # If we found any other cell(s), increment for each\n",
    "                        if len(neighbours_found) > 0:\n",
    "                            for n in neighbours_found:\n",
    "                                neighbour_counts[n] += 1\n",
    "                        else:\n",
    "                            # If no other cell was found, we store \"0\" or something to indicate no contact\n",
    "                            neighbour_counts[0] += 1\n",
    "\n",
    "                    # Build an underscore-separated string like \"2x20_3x13_0x40\"\n",
    "                    # Sort by neighbour ID for consistency\n",
    "                    sorted_neighbours = sorted(neighbour_counts.items(), key=lambda x: x[0])\n",
    "                    detail_str = \"_\".join(f\"{int(nid)}x{count}\" for (nid, count) in sorted_neighbours)\n",
    "                    cell_data[\"boundary_contacts\"] = detail_str\n",
    "\n",
    "            # Mean intensity\n",
    "            if mean:\n",
    "                for idx, marker in zip(selected_indices, selected_names):\n",
    "                    fluorescence_slice = fluorescence_stack_tensor[idx]\n",
    "                    mean_intensity = torch.mean(fluorescence_slice[cell_region]).item()\n",
    "                    cell_data[marker] = mean_intensity\n",
    "\n",
    "            # Compartment measurement\n",
    "            if compartment:\n",
    "                for comp_name, comp_mask in compartment_data.items():\n",
    "                    if compartment_measure == \"centroid\":\n",
    "                        if not np.isnan(centroid_y) and not np.isnan(centroid_x):\n",
    "                            comp_value = comp_mask[int(centroid_y), int(centroid_x)].item()\n",
    "                        else:\n",
    "                            comp_value = np.nan\n",
    "                    elif compartment_measure == \"mean\":\n",
    "                        comp_value = (torch.mean(comp_mask[cell_region]).item() \n",
    "                                      if cell_data[\"Area\"] > 0 else np.nan)\n",
    "                    elif compartment_measure == \"mode\":\n",
    "                        values, counts = torch.unique(comp_mask[cell_region], return_counts=True)\n",
    "                        comp_value = (\n",
    "                            values[torch.argmax(counts)].item() \n",
    "                            if counts.numel() > 0 else np.nan\n",
    "                        )\n",
    "                    else:\n",
    "                        raise ValueError(f\"Invalid compartment_measure: {compartment_measure}\")\n",
    "                    cell_data[comp_name] = comp_value\n",
    "\n",
    "            # Geometry\n",
    "            if geometry:\n",
    "                cell_region_cpu = cell_region.cpu().numpy()\n",
    "                contours = find_contours(cell_region_cpu, level=0.5)\n",
    "                geom = [contour.tolist() for contour in contours]\n",
    "                geom_results.append({\"Image\": name, \"CellID\": int(cell_id), \"Geometry\": geom})\n",
    "\n",
    "            # Store\n",
    "            results.append(cell_data)\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # NEAREST NEIGHBOURS\n",
    "        # ---------------------------------------------------------\n",
    "        if neighbours > 0 and shape:\n",
    "            # Build arrays for X, Y, CellID\n",
    "            coords = []\n",
    "            cellid_array = []\n",
    "            for r in results:\n",
    "                coords.append((r[\"Y\"], r[\"X\"]))   # (row, col)\n",
    "                cellid_array.append(r[\"CellID\"]) \n",
    "            \n",
    "            coords = np.array(coords)\n",
    "            cellid_array = np.array(cellid_array)\n",
    "\n",
    "            # If we have at least 2 cells with valid coords\n",
    "            if len(coords) > 1 and not np.isnan(coords).any():\n",
    "                dist_matrix = cdist(coords, coords, metric=\"euclidean\")\n",
    "\n",
    "                for i, row_dist in enumerate(dist_matrix):\n",
    "                    # i = index of the current cell\n",
    "                    # sort by ascending distance\n",
    "                    sorted_ix = np.argsort(row_dist)\n",
    "\n",
    "                    # Remove the index to itself\n",
    "                    sorted_ix = sorted_ix[sorted_ix != i]\n",
    "\n",
    "                    # Filter out neighbours that are cellID 0\n",
    "                    valid_ix = [ix for ix in sorted_ix if cellid_array[ix] != 0]\n",
    "\n",
    "                    # Now pick up to K nearest from valid_ix\n",
    "                    k = min(neighbours, len(valid_ix))\n",
    "                    nearest_ids = cellid_array[valid_ix[:k]]\n",
    "                    nearest_dists = row_dist[valid_ix[:k]]\n",
    "\n",
    "                    # Convert to underscore-separated\n",
    "                    nn_str   = \"_\".join(str(int(nid)) for nid in nearest_ids)\n",
    "                    dist_str = \"_\".join(f\"{d:.2f}\" for d in nearest_dists)\n",
    "\n",
    "                    results[i][\"nearest_neighbours\"] = nn_str\n",
    "                    results[i][\"nearest_neighbours_dist\"] = dist_str\n",
    "            else:\n",
    "                # If there's only one cell or coords are invalid:\n",
    "                for r in results:\n",
    "                    r[\"nearest_neighbours\"] = \"\"\n",
    "                    r[\"nearest_neighbours_dist\"] = \"\"\n",
    "\n",
    "        # Collect results\n",
    "        all_results.extend(results)\n",
    "        all_geom_results.extend(geom_results)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Build DataFrames and output\n",
    "    # ----------------------------------------------------------\n",
    "    final_df = pd.DataFrame(all_results)\n",
    "    geom_df  = pd.DataFrame(all_geom_results)\n",
    "\n",
    "    output_path = os.path.join(rootdir, projdir, out_dir)\n",
    "    geom_output_path = os.path.join(rootdir, projdir, geom_out_dir)\n",
    "\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    geom_df.to_csv(geom_output_path, index=False)\n",
    "\n",
    "    print(\"Processing complete.\")\n",
    "    print(\"Total time taken:\", time.time() - start_time)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "    print(f\"Geometry results saved to {geom_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyMComplete import PyProfiler\n",
    "\n",
    "PyProfiler(\n",
    "        rootdir = rootdir, \n",
    "        projdir = projdir, \n",
    "        mean = 1, \n",
    "        shape = 1, \n",
    "        geometry = 1, \n",
    "        compartment = 1,\n",
    "        compartment_measure = \"mean\",\n",
    "        panel_path = \"panel.csv\",\n",
    "        mask_dir =  \"analysis/3_segmentation/3e_cellpose_mask\",\n",
    "        image_dir = \"analysis/3_segmentation/3a_fullstack\", \n",
    "        compartment_dir =  \"analysis/3_segmentation/3f_compartments\", \n",
    "        out_dir = \"analysis/4_pyprofiler_output/cell_test.csv\",\n",
    "        geom_out_dir = \"analysis/4_pyprofiler_output/geom_test.csv\", \n",
    "        mask_suffix = \"_CpSeg_mask\",\n",
    "        image_suffix = \"_full\",\n",
    "        comp_suffix = \"_compartment\",\n",
    "        neighbours=10,         \n",
    "        boundary_contacts=1    \n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMComplete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
