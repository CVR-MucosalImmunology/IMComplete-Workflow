{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part A: Preprocessing of imaging data**  \n",
    "<i>**Latest update</i> - Dec 2024**  \n",
    "\n",
    "#### **Authors:**  \n",
    "[Oscar Dong](https://github.com/Awesomenous) (oscardong4@gmail.com) | [Thomas O'Neil](https://github.com/DrThomasOneil) (thomas.oneil@sydney.edu.au) | [Heeva Baharlou](heeva.baharlou@sydney.edu.com)  \n",
    "\n",
    "##### The purpose of this notebook is to provide a consolidated approach to IMC analysis and forms the prerequisite steps to the IMComplete R package workflow. We focused \n",
    "\n",
    "Nature Method of the Year in 2024 was [**spatial proteomics**](https://www.nature.com/articles/s41592-024-02565-3). \n",
    "\n",
    "> Computational tools for spatial proteomics are the focus of the second Comment, from Yuval Bussi and Leeat Keren. These authors note that current image processing and analysis workflow are well defined but fragmented, with various steps happening back to back rather than in an integrated fashion. They envision a future for the field where image processing and analysis steps work in concert for improved biological discovery.\n",
    "\n",
    "In response to these comments, we have committed to provide a comprehensive, complete and dynamic workflow. In part, we aimed to achieve this by compiling as much as we could into this pre-processing workflow. \n",
    "\n",
    "Particularly, we hve\n",
    "\n",
    "<hr>\n",
    "\n",
    "Some scripts adapted from [BodenmillerGroup/ImcSegmentationPipeline](https://github.com/BodenmillerGroup/ImcSegmentationPipeline) & [PENGLU-WashU/IMC_Denoise](https://github.com/PENGLU-WashU/IMC_Denoise) \n",
    "\n",
    "<i>**Therefore, make sure to also reference these studies:**</i>  \n",
    "- Windhager, J., Zanotelli, V.R.T., Schulz, D. et al. An end-to-end workflow for multiplexed image processing and analysis. [Nat Protoc](https://doi.org/10.1038/s41596-023-00881-0) (2023).  \n",
    "- Lu P, Oetjen K, Bender D, et al. IMC-Denoise: a content aware pipeline to enhance Imaging Mass Cytometry. [Nature Communications](https://www.nature.com/articles/s41467-023-37123-6), 14(1), 1601, 2023.  \n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "##### Planned future additions:  \n",
    "- Simple compartmentalisation in python widget\n",
    "- DAPI registration for improved cell segmentation\n",
    "- Integration with immunofluorescence\n",
    "- Integration with BIDCell - purpose to improve the initial segmentation mask prior to workflow.\n",
    "\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **What is in this workflow**\n",
    "\n",
    "This workflow aims to consolidate as many functions as possible in one python. The folder structure for this workflow is as follows:\n",
    "\n",
    "```text\n",
    "ImagingAnalysis/\n",
    "├── IMComplete-Workflow\n",
    "├── Experiment_name_1\n",
    "│     └── raw\n",
    "│            └── Sample1.zip\n",
    "│            └── Sample2.zip\n",
    "│            └── ...\n",
    "│     └── analysis\n",
    "│            └── 1_mcd_out\n",
    "│            └── 2_denoise\n",
    "│            └── 3_segmentation\n",
    "│                   └── 3a_fullstack\n",
    "│                   └── 3b_forSeg\n",
    "│                   └── 3c_cellpose_crop\n",
    "│                   └── 3d_cellpose_full\n",
    "│                   └── 3e_cellpose_mask\n",
    "│                   └── 3f_compartments\n",
    "│            └── 4_pyprofiler_output\n",
    "│     └── panel.csv\n",
    "├── ...\n",
    "├── Experiment_name_n\n",
    "\n",
    "\n",
    "```\n",
    "<hr> \n",
    "\n",
    "##### Below is a summary of the individual components of the workflow. Each is accompanied by a how-to video.  \n",
    "### 1. Set up\n",
    "\n",
    "Start with a root folder for your image analysis (e.g. `ImagingAnalysis`). From here, the `set up` section of this script will inform you on how to clone the [IMComplete-Workflow](https://github.com/CVR-MucosalImmunology/IMComplete-Workflow) GitHub repository. You'll also download the necessary functions from these repositories:  \n",
    "- Functions from [BodenmillerGroup/ImcSegmentationPipeline](https://github.com/BodenmillerGroup/ImcSegmentationPipeline) which allow for the images to be extracted from the MCD file format.\n",
    "- Functions from [PENGLU-WashU/IMC_Denoise](https://github.com/PENGLU-WashU/IMC_Denoise) which can be used to denoise your IMC images.\n",
    "\n",
    "These contain files that will set up the conda environment to run the necessary functions. \n",
    "\n",
    "You'll also be prompted to set up your `raw` data files (as instructed in more detail [**here**](https://github.com/BodenmillerGroup/ImcSegmentationPipeline/blob/main/scripts/imc_preprocessing.ipynb)) and `panel.csv`. A template for the panel.csv can be found in the IMComplete-Workflow once the repository is downloaded. \n",
    "\n",
    "### 2. MCD extraction\n",
    "\n",
    "\n",
    "\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Order of the analysis\n",
    "0. Set up\n",
    "1. MCD extraction\n",
    "2. Cellpose prep\n",
    "3. Cellpose model training\n",
    "4. Cellpose batch segmentation\n",
    "5. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up\n",
    "\n",
    "Anaconda is a program used to install packages needed for many steps of the pipeline to run. Follow the steps below to set up Anaconda and a `conda` environment:\n",
    "\n",
    "**Step 1:** Install [**Anaconda** ](https://www.anaconda.com/download) <br>\n",
    "**Step 2:** Once Anaconda is installed, navigate to the relevant command line interface:\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "\n",
    "| Windows                                                                                            | macOS                                                                                                      |\n",
    "|----------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|\n",
    "| 1. Search for **'Anaconda Prompt'** in the taskbar search <br> 2. Select **Anaconda Prompt**  <br> | 1. Use `cmd + space` to open Spotlight Search  <br> 2. Type **'Terminal'** and press `return` to open <br> |\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "**Step 3:** Set your directory to the analysis folder (and make folders)\n",
    "\n",
    "```bash\n",
    "cd /Desktop/ImageAnalysis\n",
    "```\n",
    "\n",
    "**Step 4:** Clone the IMComplete repository.\n",
    "\n",
    "```bash\n",
    "git clone --recursive https://github.com/CVR-MucosalImmunology/IMComplete-Workflow.git\n",
    "```\n",
    "\n",
    "**Step 5:** Create a conda environment and install some  packages (in one line)\n",
    "\n",
    "```bash\n",
    "conda env create -f dev_IMComplete-Workflow/environment.yml\n",
    "```\n",
    "**Step 6:** Activate the conda environment\n",
    "\n",
    "```bash\n",
    "conda activate IMComplete\n",
    "```\n",
    "\n",
    "**Step 7:** Clone the extra repositories:    \n",
    "- [BodenmillerGroup/ImcSegmentationPipeline](https://github.com/BodenmillerGroup/ImcSegmentationPipeline): Windhager, J., Zanotelli, V.R.T., Schulz, D. et al. An end-to-end workflow for multiplexed image processing and analysis. [Nat Protoc](https://doi.org/10.1038/s41596-023-00881-0) (2023).  \n",
    "```bash\n",
    "git clone --recursive https://github.com/BodenmillerGroup/ImcSegmentationPipeline.git\n",
    "```  \n",
    "- [PENGLU-WashU/IMC_Denoise](https://github.com/PENGLU-WashU/IMC_Denoise): Lu P, Oetjen K, Bender D, et al. IMC-Denoise: a content aware pipeline to enhance Imaging Mass Cytometry. [Nature Communications](https://www.nature.com/articles/s41467-023-37123-6), 14(1), 1601, 2023.  \n",
    "```bash\n",
    "git clone --recursive https://github.com/PENGLU-WashU/IMC_Denoise.git\n",
    "```\n",
    "\n",
    "**Step 8:** Install the packages from these two repositories\n",
    "\n",
    "```bash\n",
    "python -m pip install -e ./ImcSegmentationPipeline\n",
    "```\n",
    "```bash\n",
    "python -m pip install -e ./IMC-Denoise\n",
    "```\n",
    "\n",
    "**Step 9:** GPU-acceleration\n",
    "\n",
    "Unfortunately, parts of this workflow will require GPU-acceleration: Cell segmentation, Denoise, PyProfiler (will run quicker, but not necessary).\n",
    "\n",
    "You will need to install Pytorch and pytorch-cuda versions that are suitable for your PC. Instructions are found [here](https://pytorch.org/get-started/previous-versions/)\n",
    "\n",
    "```bash\n",
    "conda install pytorch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 pytorch-cuda=12.4 -c pytorch -c nvidia\n",
    "```\n",
    "**Step 10:** Lastly, install Cellpose\n",
    "\n",
    "```bash\n",
    "python -m pip install PyQt5 cellpose[gui] tensorflow keras\n",
    "```\n",
    "\n",
    "<hr>\n",
    "\n",
    "You can check the installation requirements with the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyMComplete\n",
    "\n",
    "PyMComplete.check_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Create a Project folder for your analysis\n",
    "\n",
    "The following function will create the folder structure for this workflow and generate a template `panel.csv`.\n",
    "\n",
    "Set `rootdir` as your `ImageAnalysis` folder directory and `projdir` as your project folder name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"D:/Dev-IMComplete\"\n",
    "projdir = \"LizIMC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyMComplete\n",
    "\n",
    "PyMComplete.newProj(rootdir, projdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Set up your raw folder\n",
    "\n",
    "Your MCD files should be zipped \n",
    "\n",
    "The [**BodenmillerGroup**](https://github.com/BodenmillerGroup/ImcSegmentationPipeline/blob/main/scripts/imc_preprocessing.ipynb) ImcSegmentationPipeline Notebook covers this more detail. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCD extraction\n",
    "\n",
    "**MCD extraction**  \n",
    "<span style=\"color:grey; opacity: 0.5\">Cellpose prep</span>  \n",
    "<span style=\"color:grey; opacity: 0.5\">Cellpose model training</span>  \n",
    "<span style=\"color:grey; opacity: 0.5\">Cellpose batch segmentation</span>    \n",
    "<span style=\"color:grey; opacity: 0.5\">Feature Extraction</span>    \n",
    "\n",
    "We have wrapped the Bodenmiller MCD extraction function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyMComplete\n",
    "import os\n",
    "\n",
    "PyMComplete.bodenmiller_mcd_extract(rootdir=rootdir,\n",
    "                                    projdir=projdir, \n",
    "                                    denoise=1, \n",
    "                                    panel=\"panel.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoise (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cellpose preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyMComplete\n",
    "\n",
    "PyMComplete.prep_cellpose(rootdir = rootdir, \n",
    "                          projdir=projdir, \n",
    "                          dna=\"191Ir_191Ir_DNA1\",\n",
    "                          extra=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna = \"191Ir_191Ir_DNA1\"\n",
    "square_size = 200\n",
    "projdir = os.path.join(rootdir,projdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, exposure, img_as_uint\n",
    "\n",
    "os.chdir(projdir)\n",
    "\n",
    "# Define directories\n",
    "dir_images =  os.path.join(projdir,\"analysis\",\"3_segmentation - adipo\",\"3b_forSeg\")\n",
    "im_output =  os.path.join(projdir,\"analysis\",\"3_segmentation - adipo\",\"3d_cellpose_full\")\n",
    "crop_output =  os.path.join(projdir,\"analysis\",\"3_segmentation - adipo\",\"3c_cellpose_crop\")\n",
    "panel_file = os.path.join(projdir,\"panel_adipo.csv\")\n",
    "\n",
    "# load image list\n",
    "image_list = [f for f in os.listdir(dir_images) if f.endswith(('.tiff', '.tif'))]\n",
    "\n",
    "# read panel\n",
    "panel = pd.read_csv(panel_file)\n",
    "segmentation_targets = panel.loc[panel['Segment'] == 1, 'Target'].tolist()\n",
    "print(\"Segmentation Targets:\", segmentation_targets)\n",
    "\n",
    "# get indices of dna channel\n",
    "dna_index = [i for i, target in enumerate(segmentation_targets) if target == dna]\n",
    "\n",
    "# crop and compress each image\n",
    "for image_file in image_list:\n",
    "    image_path = os.path.join(dir_images, image_file)\n",
    "    image = io.imread(image_path)\n",
    "    im_title = os.path.splitext(image_file)[0]\n",
    "    \n",
    "    # normalise\n",
    "    normalized_stack = []\n",
    "    for i in range(image.shape[0]): \n",
    "        channel = image[i, :, :]\n",
    "        normalized = exposure.rescale_intensity(channel, in_range='image', out_range=(0, 1))\n",
    "        normalized_stack.append(img_as_uint(normalized))\n",
    "    normalized_stack = np.stack(normalized_stack)\n",
    "    \n",
    "    # get dna channel\n",
    "    if dna_index:\n",
    "        # keep only the first instance of dna\n",
    "        dna_channel = normalized_stack[dna_index[0]]\n",
    "        \n",
    "        # remove dna from segmentation stack\n",
    "        for idx in sorted(dna_index, reverse=True):\n",
    "            normalized_stack = np.delete(normalized_stack, idx, axis=0)\n",
    "    else: #error message if dna not found\n",
    "        raise ValueError(\"DNA channel not found in segmentation targets.\")\n",
    "    \n",
    "    # create mask for surface segmentation\n",
    "    surface_mask = np.mean(normalized_stack, axis=0).astype(np.uint16)\n",
    "    \n",
    "    # create empty channel - for cellpose colour scheme to avoid red/green and combine in order empty > segment > dna\n",
    "    empty_channel = np.zeros_like(dna_channel, dtype=np.uint16)\n",
    "    # empty -> surface mask -> DNA\n",
    "    composite_stack = np.stack([empty_channel, surface_mask, dna_channel])\n",
    "    \n",
    "    # save\n",
    "    im_output_path = os.path.join(im_output, f\"{im_title}_CpSeg.tiff\")\n",
    "    io.imsave(im_output_path, composite_stack)\n",
    "    \n",
    "    # get crop dimensions\n",
    "    height, width = composite_stack.shape[1:3]\n",
    "    if width < square_size or height < square_size:\n",
    "        # if image is smaller than crop size, save image itself as the crop\n",
    "        crop_output_path = os.path.join(crop_output, f\"{im_title}_CpCrop.tiff\")\n",
    "        io.imsave(crop_output_path, composite_stack)\n",
    "        print(f\"Image {im_title} is smaller than the cropping size. Saved without cropping.\")\n",
    "        continue\n",
    "\n",
    "    # create the crop and save\n",
    "    workable_x = width - square_size\n",
    "    workable_y = height - square_size\n",
    "    rand_x = random.randint(0, workable_x)\n",
    "    rand_y = random.randint(0, workable_y)\n",
    "    cropped = composite_stack[:, rand_y:rand_y + square_size, rand_x:rand_x + square_size]\n",
    "    crop_output_path = os.path.join(crop_output, f\"{im_title}_CpCrop.tiff\")\n",
    "    io.imsave(crop_output_path, cropped)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m cellpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your required variables here\n",
    "model_path = \"D:\\Dev-IMComplete\\IFMasksOnIMCModel_HumanColon_TN3_CD12_FT1\"\n",
    "channels = [2, 3] # This means Channel 1 was 'Green' and Channel 2 was 'Blue' (1 = R, 2 = G, 3 = B)\n",
    "cell_diameter = 12.4\n",
    "flow_threshold = 3\n",
    "cellprob_threshold = -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import skimage.io\n",
    "from cellpose import models, core\n",
    "from cellpose.io import logger_setup\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Define Cellpose model\n",
    "model = models.CellposeModel(gpu=core.use_gpu(), pretrained_model=model_path)\n",
    "\n",
    "# Set and create directories\n",
    "analysis = Path(projdir)\n",
    "image_dir = analysis / \"analysis/3_segmentation/3d_cellpose_full\"\n",
    "mask_dir = analysis / \"analysis/3_segmentation/3e_cellpose_mask\"\n",
    "\n",
    "# Call logger_setup to have output of cellpose written\n",
    "logger_setup()\n",
    "\n",
    "# Get list of image files\n",
    "files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(\".tiff\")]  # Adjust the file extension if necessary\n",
    "imgs = [skimage.io.imread(f) for f in files]\n",
    "\n",
    "# Run segmentation\n",
    "masks, flows, styles = model.eval(imgs, diameter=cell_diameter, flow_threshold=flow_threshold, cellprob_threshold=cellprob_threshold, channels=channels)\n",
    "\n",
    "# Save mask images\n",
    "for idx, mask in enumerate(masks):\n",
    "    original_path = Path(files[idx])\n",
    "    new_path = mask_dir / (original_path.stem + \"_mask.tif\")\n",
    "    skimage.io.imsave(new_path, mask)\n",
    "\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyProfiler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tifffile import imread\n",
    "from scipy.ndimage import center_of_mass, find_objects\n",
    "import torch\n",
    "\n",
    "# Arguments to control data collection\n",
    "mean = 1  # Collect mean fluorescence\n",
    "shape = 1  # Collect shape metrics (Area, Eccentricity)\n",
    "geometry = 1  # Collect geometry (contours)\n",
    "compartment = 1  # Collect compartment metrics\n",
    "\n",
    "# Check for CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(projdir)\n",
    "\n",
    "# Define directories for masks, stacks, and compartments\n",
    "masks_dir = os.path.join(projdir, \"analysis/3_segmentation/3e_cellpose_mask\")\n",
    "stacks_dir = os.path.join(projdir, \"analysis/3_segmentation/3a_fullstack\")\n",
    "compartments_dir = os.path.join(projdir, \"analysis/3_segmentation/3f_compartments\")\n",
    "\n",
    "# Get list of masks and stacks\n",
    "mask_files = [f for f in os.listdir(masks_dir) if f.endswith(('.tif', '.tiff'))]\n",
    "stack_files = [f for f in os.listdir(stacks_dir) if f.endswith(('.tif', '.tiff'))]\n",
    "\n",
    "# Match mask and stack files by name\n",
    "image_names = [os.path.splitext(f)[0].replace(\"_segment_CpSeg_mask\", \"\") for f in mask_files]\n",
    "\n",
    "# Identify compartments if applicable\n",
    "if compartment:\n",
    "    compartment_folders = [f for f in os.listdir(compartments_dir) if os.path.isdir(os.path.join(compartments_dir, f))]\n",
    "    if not compartment_folders:\n",
    "        print(\"No folders found in the compartments directory. Disabling compartment processing.\")\n",
    "        compartment = 0\n",
    "    else:\n",
    "        compartment_masks = {}\n",
    "        for folder in compartment_folders:\n",
    "            folder_path = os.path.join(compartments_dir, folder)\n",
    "            compartment_masks[folder] = {\n",
    "                name: os.path.join(folder_path, f)\n",
    "                for f in os.listdir(folder_path)\n",
    "                if f.endswith(('.tif', '.tiff'))\n",
    "            }\n",
    "\n",
    "# Process each image\n",
    "all_results = []\n",
    "start_time = time.time()\n",
    "\n",
    "for name in image_names:\n",
    "    print(f\"Processing {name}...\")\n",
    "\n",
    "    # Load mask and stack\n",
    "    mask_path = os.path.join(masks_dir, f\"{name}_segment_CpSeg_mask.tif\")\n",
    "    stack_path = os.path.join(stacks_dir, f\"{name}_full.tiff\")\n",
    "\n",
    "    cell_mask = imread(mask_path)  # Single-layer TIFF mask\n",
    "    fluorescence_stack = imread(stack_path)  # Multi-layer TIFF\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    cell_mask_tensor = torch.tensor(cell_mask, device=device, dtype=torch.int32)\n",
    "    fluorescence_stack_tensor = torch.tensor(fluorescence_stack, device=device, dtype=torch.float32)\n",
    "\n",
    "    # Load panel.csv file\n",
    "    panel_path = os.path.join(projdir, \"panel.csv\")\n",
    "    panel = pd.read_csv(panel_path)\n",
    "    selected_markers = panel[panel['Full'] == 1].reset_index(drop=True)\n",
    "    selected_indices = range(len(selected_markers))  # Indices correspond to stack order\n",
    "    selected_names = selected_markers['Target'].values  # Names of relevant markers\n",
    "\n",
    "    # Extract unique CellIDs (include CellID 0 for background)\n",
    "    cell_ids = torch.unique(cell_mask_tensor).cpu().numpy()\n",
    "\n",
    "    # Initialize results for this image\n",
    "    results = []\n",
    "\n",
    "    # Check for compartment masks\n",
    "    missing_compartments = []\n",
    "    compartment_data = {}\n",
    "    if compartment:\n",
    "        for comp_name, comp_files in compartment_masks.items():\n",
    "            comp_file = comp_files.get(f\"{name}_compartment.tiff\")\n",
    "            if not comp_file:\n",
    "                missing_compartments.append(comp_name)\n",
    "            else:\n",
    "                compartment_data[comp_name] = torch.tensor(imread(comp_file), device=device, dtype=torch.float32)\n",
    "\n",
    "        if missing_compartments:\n",
    "            action = input(f\"Missing compartments {missing_compartments} for {name}. Choose action: \\n1) Continue with NA\\n2) Stop\\n3) Ignore compartment data\\nEnter choice: \")\n",
    "            if action == \"2\":\n",
    "                print(\"Stopping execution. Please address missing compartments.\")\n",
    "                exit()\n",
    "            elif action == \"3\":\n",
    "                compartment = 0\n",
    "                compartment_data = {}\n",
    "\n",
    "    # Process each cell\n",
    "    for cell_id in cell_ids:\n",
    "        cell_region = (cell_mask_tensor == cell_id)\n",
    "        cell_data = {\"Image\": name, \"CellID\": int(cell_id)}\n",
    "\n",
    "        if shape:\n",
    "            # Area\n",
    "            cell_data[\"Area\"] = int(torch.sum(cell_region).item())\n",
    "\n",
    "            # Centroid\n",
    "            if torch.any(cell_region):\n",
    "                indices = torch.nonzero(cell_region, as_tuple=True)\n",
    "                centroid_y = torch.mean(indices[0].float()).item()\n",
    "                centroid_x = torch.mean(indices[1].float()).item()\n",
    "            else:\n",
    "                centroid_y, centroid_x = np.nan, np.nan\n",
    "            cell_data[\"CentroidX\"] = centroid_x\n",
    "            cell_data[\"CentroidY\"] = centroid_y\n",
    "\n",
    "            # Bounding box and Eccentricity\n",
    "            bbox_indices = torch.nonzero(cell_region)\n",
    "            if bbox_indices.shape[0] > 0:\n",
    "                height = bbox_indices[:, 0].max().item() - bbox_indices[:, 0].min().item() + 1\n",
    "                width = bbox_indices[:, 1].max().item() - bbox_indices[:, 1].min().item() + 1\n",
    "                cell_data[\"Eccentricity\"] = height / width if width != 0 else np.nan\n",
    "            else:\n",
    "                cell_data[\"Eccentricity\"] = np.nan\n",
    "\n",
    "        if mean:\n",
    "            for idx, marker in zip(selected_indices, selected_names):\n",
    "                fluorescence_slice = fluorescence_stack_tensor[idx]\n",
    "                mean_intensity = torch.mean(fluorescence_slice[cell_region].float()).item() / 65535  # Normalize to 16-bit range\n",
    "                cell_data[marker] = mean_intensity\n",
    "\n",
    "        if compartment:\n",
    "            for comp_name, comp_mask in compartment_data.items():\n",
    "                comp_region = comp_mask[cell_region]\n",
    "                comp_mean = torch.sum(comp_region).item() / cell_data[\"Area\"] if cell_data[\"Area\"] > 0 else np.nan\n",
    "                cell_data[comp_name] = comp_mean\n",
    "\n",
    "        # Append cell data to results\n",
    "        results.append(cell_data)\n",
    "\n",
    "    # Append image results to all results\n",
    "    all_results.extend(results)\n",
    "\n",
    "# Create a DataFrame from all results\n",
    "final_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = os.path.join(projdir, \"analysis/4_pyprofiler_output/cell_data_combined.csv\")\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Processing complete.\")\n",
    "print(\"Total time taken:\", time.time() - start_time)\n",
    "print(f\"Results saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMComplete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
